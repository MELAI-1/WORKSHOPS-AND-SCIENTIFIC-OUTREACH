{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MELAI-1/WORKSHOPS-AND-SCIENTIFIC-OUTREACH/blob/main/I-X%20AI%20in%20Science-Imperial/Tutorial_Phylodynamics_ModelSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTpir9J3OK1d"
      },
      "source": [
        "# **Tutorial for phylodynamics model selection**\n",
        "Based on the method developed in Perez M.F. and Gascuel O.PhyloCNN: Improving tree representation and neural network architecture for deep learning from trees in phylodynamics and diversification studies. https://www.biorxiv.org/content/10.1101/2024.12.13.628187v1\n",
        "\n",
        "## **1. Introduction**\n",
        "This tutorial shows how to train a CNN model that classify phylogentic trees of viruses according to three competing epidemiological (phylodynamics) models.\n",
        "\n",
        "Phylodynamics relies on phylogenetic trees, which are build based on aligned genetic sequences of the pathogen taken from infecte individuals. The trees are calibrated (dated) to reflect transmission times.\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1sQ4hClFJs9xZoSo_ScmtuxYMoa05RSXh\" width=\"600\" height=\"300\">\n",
        "\n",
        "Figure 1. from [Guinat et al., 2021](https://www.sciencedirect.com/science/article/pii/S0169534721001300).\n",
        "\n",
        "We will compare three competing epidemiological (phylodynamics) models - Birth-Death (BD), Birth-Death Exposed Infectious (BDEI) and Birth-Death with Superspreaders (BDSS).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FxkO0Qisu6m1_Znc76MMbd6ZVUSPWuAl\" width=\"500\" height=\"300\">\n",
        "\n",
        "The simulated trees were encoded by describing the neighborhood (e.g., length of outgoing branches) and main measurements (e.g., date, number of descendants) of all nodes and leaves of the phylogeny.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FysAnN2H8C312yQFtAWeFW7OSRAAMdrv\" width=\"750\" height=\"750\">\n",
        "\n",
        "## **2. Libraries and Data Loading**\n",
        "We import the required python libraries and then we load phylogenetic trees simulated under each of the 3 models (BD, BDEI, BDSS).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First you need to download the data.\n",
        "!gdown --id 1GHLYw3EezrtrMkJDBXY8FNZ4FjyV3Vnn"
      ],
      "metadata": {
        "id": "Dru4AD6NQf51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe1c69a-be72-425d-df90-2ce1406491a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1GHLYw3EezrtrMkJDBXY8FNZ4FjyV3Vnn\n",
            "From (redirected): https://drive.google.com/uc?id=1GHLYw3EezrtrMkJDBXY8FNZ4FjyV3Vnn&confirm=t&uuid=f17779ba-4cfa-4be3-8390-997cfe194625\n",
            "To: /content/PhyloDyn.zip\n",
            "100% 70.1M/70.1M [00:00<00:00, 128MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip simulations\n",
        "!unzip \"/content/PhyloDyn.zip\""
      ],
      "metadata": {
        "id": "1XUj4uRMTAbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91c0175-a9b3-49bd-ade1-7840c3897afa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/PhyloDyn.zip\n",
            "   creating: PhyloDyn/\n",
            "  inflating: __MACOSX/._PhyloDyn     \n",
            "  inflating: PhyloDyn/.DS_Store 2    \n",
            "  inflating: __MACOSX/PhyloDyn/._.DS_Store 2  \n",
            "  inflating: PhyloDyn/.DS_Store      \n",
            "  inflating: __MACOSX/PhyloDyn/._.DS_Store  \n",
            "  inflating: PhyloDyn/Encoded_Zurich.csv  \n",
            "  inflating: __MACOSX/PhyloDyn/._Encoded_Zurich.csv  \n",
            "  inflating: PhyloDyn/BDSS_large_100K.csv  \n",
            "  inflating: __MACOSX/PhyloDyn/._BDSS_large_100K.csv  \n",
            "  inflating: PhyloDyn/Encoded_Zurich.npy  \n",
            "  inflating: __MACOSX/PhyloDyn/._Encoded_Zurich.npy  \n",
            "   creating: PhyloDyn/testset/\n",
            "  inflating: __MACOSX/PhyloDyn/._testset  \n",
            "  inflating: PhyloDyn/Encoded_trees_BDSS.npy  \n",
            "  inflating: __MACOSX/PhyloDyn/._Encoded_trees_BDSS.npy  \n",
            "  inflating: PhyloDyn/Encoded_trees_BDEI.npy  \n",
            "  inflating: __MACOSX/PhyloDyn/._Encoded_trees_BDEI.npy  \n",
            "  inflating: PhyloDyn/Encoded_trees_BD.npy  \n",
            "  inflating: __MACOSX/PhyloDyn/._Encoded_trees_BD.npy  \n",
            "  inflating: PhyloDyn/testset/.DS_Store  \n",
            "  inflating: __MACOSX/PhyloDyn/testset/._.DS_Store  \n",
            "  inflating: PhyloDyn/testset/BDSS_large_10000.csv  \n",
            "  inflating: __MACOSX/PhyloDyn/testset/._BDSS_large_10000.csv  \n",
            "  inflating: PhyloDyn/testset/Encoded_trees_BDSS.npy  \n",
            "  inflating: __MACOSX/PhyloDyn/testset/._Encoded_trees_BDSS.npy  \n",
            "  inflating: PhyloDyn/testset/Encoded_trees_BDEI.npy  \n",
            "  inflating: __MACOSX/PhyloDyn/testset/._Encoded_trees_BDEI.npy  \n",
            "  inflating: PhyloDyn/testset/Encoded_trees_BD.npy  \n",
            "  inflating: __MACOSX/PhyloDyn/testset/._Encoded_trees_BD.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "GmQp3Do2OK1f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import Conv2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 1) Load tree encodings for BD, BDEI, BDSS models. For each model, we will load tree\n",
        "# encodings for training (1,000 trees per model) and for testing (testset - 100 trees per model).\n",
        "# The encodings are separated in two channels (one for internal nodes and another\n",
        "# for the leaves of the tree). The trees have a maximum of 500 tips (leaves).\n",
        "encoding_BD = np.load('/content/PhyloDyn/Encoded_trees_BD.npy')\n",
        "encoding_test_BD = np.load('/content/PhyloDyn/testset/Encoded_trees_BD.npy')\n",
        "encoding_BDEI  = np.load('/content/PhyloDyn/Encoded_trees_BDEI.npy')\n",
        "encoding_test_BDEI = np.load('/content/PhyloDyn/testset/Encoded_trees_BDEI.npy')\n",
        "encoding_BDSS  = np.load('/content/PhyloDyn/Encoded_trees_BDSS.npy')\n",
        "encoding_test_BDSS = np.load('/content/PhyloDyn/testset/Encoded_trees_BDSS.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 1: Data Visualization\n",
        "\n",
        "**Question 1a (add code below and copy it on your assessment form at the end):** Fill the code cell below to check the shape of the loaded inputs for training trees and test trees."
      ],
      "metadata": {
        "id": "2v98FriXb5PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add code below to recover the shape from encodings of training and test trees.\n",
        "print(f\"the shape of the encodings of Birth-Death (BD) train tree is\",encoding_BD.shape)\n",
        "print(f\"the shape of the encodings of Birth-Death (BD) test tree is\",encoding_test_BD.shape)\n",
        "print(f\"the shape of the encodings of Birth-Death Exposed Infectious (BDEI) train tree is\",encoding_BDEI.shape)\n",
        "print(f\"the shape of the encodings of Birth-Death Exposed Infectious (BDEI) test tree is\",encoding_test_BDEI.shape)\n",
        "print(f\"the shape of the encodings of Birth-Death with Superspreaders (BDSS)train tree is\",encoding_BDSS.shape)\n",
        "print(f\"the shape of the encodings of Birth-Death with Superspreaders (BDSS) test tree is\",encoding_test_BDSS.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "uWD4nvudSUT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b83eb3-c84d-44a5-f8c8-d962f4d173ba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shape of the encodings of Birth-Death (BD) train tree is (1000, 500, 19, 2)\n",
            "the shape of the encodings of Birth-Death (BD) test tree is (100, 500, 19, 2)\n",
            "the shape of the encodings of Birth-Death Exposed Infectious (BDEI) train tree is (1000, 500, 19, 2)\n",
            "the shape of the encodings of Birth-Death Exposed Infectious (BDEI) test tree is (100, 500, 19, 2)\n",
            "the shape of the encodings of Birth-Death with Superspreaders (BDSS)train tree is (1000, 500, 19, 2)\n",
            "the shape of the encodings of Birth-Death with Superspreaders (BDSS) test tree is (100, 500, 19, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1b (add the answer to your assessment form):** What does the second dimension (value 500) in the arrays represent?\n",
        "- A. The number of simulations  \n",
        "- B. The number of features per node  \n",
        "- C. The number of mavimum leaves per tree  \n",
        "- D. The number of epidemiological models  "
      ],
      "metadata": {
        "id": "Z0il1Q-FWz1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "answer:\n",
        "c-The number of maximum leaves per tree"
      ],
      "metadata": {
        "id": "kc48nifxzTcY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dV0S2DXOK1g"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "We will process the input to be properly formatted before feeding it to the neural network. This will involve the following steps:\n",
        "\n",
        "### Label Assignment\n",
        "We create a label array **Y** for the training and test set, with:\n",
        "- `0` for BD\n",
        "- `1` for BDEI\n",
        "- `2` for BDSS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "xjVNkxGHOK1g"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Add labels for each simulation (a different label for each model)\n",
        "Y = [0 for i in range(len(encoding_BD))]\n",
        "Y.extend([1 for i in range(len(encoding_BDEI))])\n",
        "Y.extend([2 for i in range(len(encoding_BDSS))])\n",
        "Y = np.array(Y)\n",
        "\n",
        "Y_test = [0 for i in range(len(encoding_test_BD))]\n",
        "Y_test.extend([1 for i in range(len(encoding_test_BDEI))])\n",
        "Y_test.extend([2 for i in range(len(encoding_test_BDSS))])\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "#We **one-hot encode** `Y` (since it’s a 3-class classification)\n",
        "Y = np.eye(3)[Y]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine encodings from the 3 models\n",
        "encoding = np.concatenate((encoding_BD,encoding_BDEI,encoding_BDSS),axis=0)\n",
        "encoding_test = np.concatenate((encoding_test_BD,encoding_test_BDEI,encoding_test_BDSS),axis=0)"
      ],
      "metadata": {
        "id": "d7jHL3JaZBjm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Splitting Data into Training & Validation\n",
        "# 30% for validation\n",
        "Y, Y_valid, encoding, encoding_valid = train_test_split(Y,encoding,test_size=0.3, shuffle=True,stratify=Y)"
      ],
      "metadata": {
        "id": "zQWCTwkTcbJT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 2: Data split and stratification\n",
        "\n",
        "**Question 2 (add explanation to the assessment form):** a) What is the validation set and why is it useful? b) Why do we need to shuffle the order of labels and trees? c) What is the advantage to using 'stratify=Y' in our example?"
      ],
      "metadata": {
        "id": "FN7Eq9Z5cfGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answers:\n",
        "a) The validation set is a portion of the dataset set aside to evaluate a model's performance during training, and it is useful because it enables hyperparameter tuning, early stopping to prevent overfitting, provides realistic estimates of model generalization to unseen data, and facilitates comparisons between models based on performance metrics.\n",
        "\n",
        "b) We need to shuffle the order of labels and trees to eliminate any order bias that may exist, ensure that both training and validation sets are representative of the entire dataset, prevent overfitting to sequence patterns in ensemble methods, and avoid biased distributions in cross-validation folds.\n",
        "\n",
        "c) The advantage of using stratify=Y is that it ensures that the proportions of different classes in the dataset are preserved in both the training and validation sets, leading to more reliable and consistent model evaluation."
      ],
      "metadata": {
        "id": "fBVe9uYfvubY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGRschtsOK1i"
      },
      "source": [
        "## 4. Building & Training the CNN (2-Generation Context)\n",
        "\n",
        "### Model Definition\n",
        "We define a CNN that processes input of shape `(500, 19, 2)`:\n",
        "- 500 = number of leaves or nodes\n",
        "- 19 = number of features\n",
        "- 2 = channels (leaves, nodes)\n",
        "\n",
        "This architecture was inspired by the fact that internal nodes and leaves contribute differently to the tree likelihood calculation for multi-type birth-death models (MTBD, which includes BD, BDEI and BDSS; see Equation 8 in [Zhukova et al., 2023](https://academic.oup.com/sysbio/article/72/6/1387/7273092))\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FvkaeBLF42DuYYgePIj3NhKetzK3Abj6\" width=\"1000\" height=\"500\">\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Fzol42i8u8hvSC6DEMDM3ScsoyeW4TTx\" width=\"500\" height=\"340\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Build the Neural Network Model <p id=\"build\"> </p>"
      ],
      "metadata": {
        "id": "ci-5jh2_du7W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "X1gsAq8gOK1i"
      },
      "outputs": [],
      "source": [
        "# Creation of the Network Model: model definition\n",
        "def build_model():\n",
        "    # Initialize the Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # First convolutional layer:\n",
        "    # - Filters: 32\n",
        "    # - Kernel size: (1, 19), sliding across the second dimension of the input\n",
        "    # - Input shape: (500, 19, 2) where 500 is the number of tree leaves/nodes, 19 is the feature size, and 2 is the number of channels (leaves and nodes)\n",
        "    # - Activation function: ELU (Exponential Linear Unit)\n",
        "    # - Groups: 2 to apply separate convolutions for the two channels (leaves and nodes)\n",
        "    model.add(Conv2D(filters=32, use_bias=False, kernel_size=(1, 19), input_shape=(500, 19, 2), activation='relu', groups=2))\n",
        "\n",
        "    # Apply batch normalization to stabilize and speed up the training process\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Second convolutional layer:\n",
        "    # - Filters: 32\n",
        "    # - Kernel size: (1, 1) to process each feature independently\n",
        "    # - Activation function: ELU\n",
        "    model.add(Conv2D(filters=32, use_bias=False, kernel_size=(1, 1), activation='relu'))\n",
        "\n",
        "    # Apply batch normalization again\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Third convolutional layer:\n",
        "    # - Filters: 32\n",
        "    # - Kernel size: (1, 1) for further feature processing\n",
        "    # - Activation function: ELU\n",
        "    model.add(Conv2D(filters=32, use_bias=False, kernel_size=(1, 1), activation='relu'))\n",
        "\n",
        "    # Apply batch normalization for the final time before flattening\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Flatten the 2D feature maps from the convolutional layers into a 1D vector,\n",
        "    # which will be passed to the fully connected (dense) layers\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    # Fully connected (FFNN) part:\n",
        "    # Dense layers with decreasing number of units, all using ELU activation:\n",
        "    model.add(Dense(64, activation='relu'))   # First dense layer with 64 units\n",
        "    model.add(Dense(32, activation='relu'))   # Second dense layer with 32 units\n",
        "    model.add(Dense(16, activation='relu'))   # Third dense layer with 16 units\n",
        "    model.add(Dense(8, activation='relu'))    # Fourth dense layer with 8 units\n",
        "\n",
        "    # Output layer:\n",
        "    # - 3 output neurons, corresponding to the 3 models\n",
        "    # - Activation function: softmax\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    # Show the summary of the model structure (number of layers, shapes of outputs, etc.)\n",
        "    model.summary()\n",
        "\n",
        "    # Return the constructed model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOohM7-uOK1i"
      },
      "source": [
        "Now we compile and fit the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "EIl2-8hzOK1j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4112f4dd-f4c8-4163-b426-ae710a37cbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m608\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,923\u001b[0m (30.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,923</span> (30.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,731\u001b[0m (30.20 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,731</span> (30.20 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3457 - loss: 1.0920\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.3464 - loss: 1.0916 - val_accuracy: 0.4444 - val_loss: 1.0723\n",
            "Epoch 2/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5962 - loss: 0.8341 - val_accuracy: 0.5989 - val_loss: 0.7598\n",
            "Epoch 3/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6309 - loss: 0.5898 - val_accuracy: 0.6511 - val_loss: 0.7612\n",
            "Epoch 4/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8128 - loss: 0.4774 - val_accuracy: 0.6500 - val_loss: 0.6574\n",
            "Epoch 5/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8636 - loss: 0.3515 - val_accuracy: 0.5578 - val_loss: 0.8360\n",
            "Epoch 6/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8956 - loss: 0.2976 - val_accuracy: 0.6378 - val_loss: 0.7377\n",
            "Epoch 7/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8628 - loss: 0.3393 - val_accuracy: 0.6911 - val_loss: 0.9654\n",
            "Epoch 8/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8952 - loss: 0.2648 - val_accuracy: 0.8589 - val_loss: 0.3510\n",
            "Epoch 9/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8970 - loss: 0.2659 - val_accuracy: 0.8944 - val_loss: 0.2919\n",
            "Epoch 10/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9134 - loss: 0.2279 - val_accuracy: 0.9100 - val_loss: 0.2438\n",
            "Epoch 11/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9249 - loss: 0.2113 - val_accuracy: 0.8833 - val_loss: 0.3207\n",
            "Epoch 12/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9149 - loss: 0.2093 - val_accuracy: 0.7622 - val_loss: 0.6380\n",
            "Epoch 13/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9145 - loss: 0.2361 - val_accuracy: 0.8678 - val_loss: 0.3286\n",
            "Epoch 14/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9251 - loss: 0.2111 - val_accuracy: 0.8644 - val_loss: 0.3542\n",
            "Epoch 15/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9267 - loss: 0.2120 - val_accuracy: 0.9056 - val_loss: 0.2640\n",
            "Epoch 16/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9182 - loss: 0.2194 - val_accuracy: 0.8289 - val_loss: 0.4762\n",
            "Epoch 17/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9312 - loss: 0.1959 - val_accuracy: 0.6844 - val_loss: 1.0408\n",
            "Epoch 18/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9193 - loss: 0.2238 - val_accuracy: 0.8000 - val_loss: 0.5577\n",
            "Epoch 19/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9261 - loss: 0.1917 - val_accuracy: 0.8644 - val_loss: 0.3471\n",
            "Epoch 20/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9253 - loss: 0.1992 - val_accuracy: 0.7522 - val_loss: 0.7932\n",
            "Epoch 21/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9393 - loss: 0.1696 - val_accuracy: 0.9167 - val_loss: 0.2278\n",
            "Epoch 22/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9492 - loss: 0.1589 - val_accuracy: 0.8722 - val_loss: 0.3007\n",
            "Epoch 23/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9283 - loss: 0.1742 - val_accuracy: 0.9144 - val_loss: 0.2315\n",
            "Epoch 24/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9367 - loss: 0.1747 - val_accuracy: 0.7589 - val_loss: 0.7267\n",
            "Epoch 25/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9276 - loss: 0.1848 - val_accuracy: 0.8856 - val_loss: 0.2948\n",
            "Epoch 26/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9373 - loss: 0.1615 - val_accuracy: 0.9022 - val_loss: 0.2536\n",
            "Epoch 27/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9390 - loss: 0.1712 - val_accuracy: 0.8633 - val_loss: 0.3925\n",
            "Epoch 28/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9485 - loss: 0.1542 - val_accuracy: 0.9067 - val_loss: 0.2829\n",
            "Epoch 29/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9452 - loss: 0.1577 - val_accuracy: 0.5989 - val_loss: 1.8532\n",
            "Epoch 30/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9352 - loss: 0.1898 - val_accuracy: 0.8267 - val_loss: 0.5021\n",
            "Epoch 31/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9273 - loss: 0.1833 - val_accuracy: 0.8922 - val_loss: 0.2866\n",
            "Epoch 32/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9415 - loss: 0.1732 - val_accuracy: 0.7411 - val_loss: 0.7629\n",
            "Epoch 33/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9371 - loss: 0.1700 - val_accuracy: 0.9044 - val_loss: 0.2724\n",
            "Epoch 34/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9415 - loss: 0.1687 - val_accuracy: 0.7567 - val_loss: 0.7127\n",
            "Epoch 35/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9360 - loss: 0.1733 - val_accuracy: 0.6456 - val_loss: 1.3947\n",
            "Epoch 36/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9382 - loss: 0.1662 - val_accuracy: 0.9222 - val_loss: 0.2348\n",
            "Epoch 37/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9492 - loss: 0.1425 - val_accuracy: 0.6833 - val_loss: 1.1421\n",
            "Epoch 38/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9415 - loss: 0.1597 - val_accuracy: 0.6889 - val_loss: 0.9868\n",
            "Epoch 39/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9467 - loss: 0.1515 - val_accuracy: 0.8544 - val_loss: 0.4027\n",
            "Epoch 40/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9482 - loss: 0.1423 - val_accuracy: 0.6889 - val_loss: 1.3739\n",
            "Epoch 41/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9431 - loss: 0.1443 - val_accuracy: 0.8522 - val_loss: 0.4187\n",
            "Epoch 42/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9542 - loss: 0.1335 - val_accuracy: 0.8867 - val_loss: 0.3180\n",
            "Epoch 43/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9497 - loss: 0.1367 - val_accuracy: 0.8444 - val_loss: 0.5318\n",
            "Epoch 44/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9446 - loss: 0.1397 - val_accuracy: 0.6189 - val_loss: 1.9709\n",
            "Epoch 45/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9524 - loss: 0.1321 - val_accuracy: 0.6322 - val_loss: 1.0627\n",
            "Epoch 46/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9459 - loss: 0.1414 - val_accuracy: 0.9111 - val_loss: 0.2356\n",
            "Epoch 47/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9397 - loss: 0.1620 - val_accuracy: 0.8722 - val_loss: 0.3854\n",
            "Epoch 48/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9381 - loss: 0.1550 - val_accuracy: 0.4678 - val_loss: 3.1024\n",
            "Epoch 49/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9508 - loss: 0.1302 - val_accuracy: 0.8367 - val_loss: 0.5152\n",
            "Epoch 50/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9584 - loss: 0.1133 - val_accuracy: 0.3456 - val_loss: 5.8385\n",
            "Epoch 51/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9413 - loss: 0.1487 - val_accuracy: 0.7589 - val_loss: 0.6949\n",
            "Epoch 52/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9541 - loss: 0.1285 - val_accuracy: 0.4744 - val_loss: 4.0043\n",
            "Epoch 53/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9501 - loss: 0.1321 - val_accuracy: 0.8811 - val_loss: 0.3178\n",
            "Epoch 54/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9381 - loss: 0.1554 - val_accuracy: 0.9067 - val_loss: 0.2641\n",
            "Epoch 55/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9320 - loss: 0.1511 - val_accuracy: 0.8456 - val_loss: 0.4977\n",
            "Epoch 56/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9503 - loss: 0.1265 - val_accuracy: 0.8411 - val_loss: 0.4789\n",
            "Epoch 57/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9550 - loss: 0.1276 - val_accuracy: 0.8489 - val_loss: 0.4703\n",
            "Epoch 58/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9450 - loss: 0.1377 - val_accuracy: 0.6033 - val_loss: 2.5571\n",
            "Epoch 59/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.1163 - val_accuracy: 0.7789 - val_loss: 0.7759\n",
            "Epoch 60/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9499 - loss: 0.1270 - val_accuracy: 0.8278 - val_loss: 0.6270\n",
            "Epoch 61/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.1128 - val_accuracy: 0.7589 - val_loss: 0.7557\n",
            "Epoch 62/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.1163 - val_accuracy: 0.8967 - val_loss: 0.3343\n",
            "Epoch 63/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9593 - loss: 0.1180 - val_accuracy: 0.7844 - val_loss: 0.6567\n",
            "Epoch 64/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.1160 - val_accuracy: 0.9056 - val_loss: 0.2488\n",
            "Epoch 65/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9669 - loss: 0.0958 - val_accuracy: 0.9256 - val_loss: 0.2297\n",
            "Epoch 66/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9561 - loss: 0.1221 - val_accuracy: 0.8544 - val_loss: 0.6040\n",
            "Epoch 67/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.1082 - val_accuracy: 0.8611 - val_loss: 0.3598\n",
            "Epoch 68/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9536 - loss: 0.1161 - val_accuracy: 0.7911 - val_loss: 0.8568\n",
            "Epoch 69/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.1641 - val_accuracy: 0.6556 - val_loss: 2.4221\n",
            "Epoch 70/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9627 - loss: 0.1024 - val_accuracy: 0.8711 - val_loss: 0.3440\n",
            "Epoch 71/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9606 - loss: 0.1078 - val_accuracy: 0.8811 - val_loss: 0.3167\n",
            "Epoch 72/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9597 - loss: 0.1068 - val_accuracy: 0.5656 - val_loss: 1.9690\n",
            "Epoch 73/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9585 - loss: 0.1071 - val_accuracy: 0.6400 - val_loss: 1.3424\n",
            "Epoch 74/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9586 - loss: 0.1102 - val_accuracy: 0.9133 - val_loss: 0.2481\n",
            "Epoch 75/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9716 - loss: 0.0907 - val_accuracy: 0.9189 - val_loss: 0.2398\n",
            "Epoch 76/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9592 - loss: 0.1040 - val_accuracy: 0.8667 - val_loss: 0.4749\n",
            "Epoch 77/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9516 - loss: 0.1154 - val_accuracy: 0.9111 - val_loss: 0.3160\n",
            "Epoch 78/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.0877 - val_accuracy: 0.8978 - val_loss: 0.4497\n",
            "Epoch 79/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9601 - loss: 0.1022 - val_accuracy: 0.4433 - val_loss: 4.6068\n",
            "Epoch 80/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9530 - loss: 0.1158 - val_accuracy: 0.8800 - val_loss: 0.4512\n",
            "Epoch 81/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.1121 - val_accuracy: 0.8800 - val_loss: 0.3700\n",
            "Epoch 82/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.1166 - val_accuracy: 0.5744 - val_loss: 2.0404\n",
            "Epoch 83/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.0842 - val_accuracy: 0.8311 - val_loss: 0.8207\n",
            "Epoch 84/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9594 - loss: 0.0996 - val_accuracy: 0.9022 - val_loss: 0.3430\n",
            "Epoch 85/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.0744 - val_accuracy: 0.8289 - val_loss: 0.5722\n",
            "Epoch 86/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9732 - loss: 0.0715 - val_accuracy: 0.7789 - val_loss: 0.8550\n",
            "Epoch 87/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9666 - loss: 0.0858 - val_accuracy: 0.8389 - val_loss: 0.4522\n",
            "Epoch 88/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9715 - loss: 0.0806 - val_accuracy: 0.8178 - val_loss: 0.7699\n",
            "Epoch 89/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9693 - loss: 0.0872 - val_accuracy: 0.5944 - val_loss: 3.1330\n",
            "Epoch 90/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9651 - loss: 0.1008 - val_accuracy: 0.5333 - val_loss: 3.0120\n",
            "Epoch 91/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9655 - loss: 0.0928 - val_accuracy: 0.9178 - val_loss: 0.2865\n",
            "Epoch 92/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9723 - loss: 0.0799 - val_accuracy: 0.8633 - val_loss: 0.6426\n",
            "Epoch 93/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9706 - loss: 0.0865 - val_accuracy: 0.6333 - val_loss: 2.3758\n",
            "Epoch 94/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9656 - loss: 0.0941 - val_accuracy: 0.6567 - val_loss: 1.5389\n",
            "Epoch 95/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9598 - loss: 0.0966 - val_accuracy: 0.8944 - val_loss: 0.3452\n",
            "Epoch 96/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9677 - loss: 0.0763 - val_accuracy: 0.6633 - val_loss: 1.8130\n",
            "Epoch 97/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9694 - loss: 0.0848 - val_accuracy: 0.5778 - val_loss: 2.5336\n",
            "Epoch 98/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9752 - loss: 0.0738 - val_accuracy: 0.7444 - val_loss: 1.5998\n",
            "Epoch 99/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0707 - val_accuracy: 0.7133 - val_loss: 1.5242\n",
            "Epoch 100/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9738 - loss: 0.0856 - val_accuracy: 0.5678 - val_loss: 2.9161\n",
            "Epoch 101/1000\n",
            "\u001b[1m64/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9665 - loss: 0.0852\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9666 - loss: 0.0852 - val_accuracy: 0.5500 - val_loss: 3.8694\n",
            "Epoch 102/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 0.0777 - val_accuracy: 0.7967 - val_loss: 0.6308\n",
            "Epoch 103/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.1146 - val_accuracy: 0.9089 - val_loss: 0.2950\n",
            "Epoch 104/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9729 - loss: 0.0766 - val_accuracy: 0.9000 - val_loss: 0.2980\n",
            "Epoch 105/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0934 - val_accuracy: 0.7011 - val_loss: 1.3541\n",
            "Epoch 106/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9704 - loss: 0.0781 - val_accuracy: 0.8144 - val_loss: 0.6599\n",
            "Epoch 107/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9651 - loss: 0.0911 - val_accuracy: 0.8722 - val_loss: 0.5713\n",
            "Epoch 108/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9654 - loss: 0.0970 - val_accuracy: 0.7689 - val_loss: 1.1379\n",
            "Epoch 109/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.0781 - val_accuracy: 0.3556 - val_loss: 8.9327\n",
            "Epoch 110/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9776 - loss: 0.0630 - val_accuracy: 0.4800 - val_loss: 6.0841\n",
            "Epoch 111/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0580 - val_accuracy: 0.6178 - val_loss: 2.5105\n",
            "Epoch 112/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0430 - val_accuracy: 0.9011 - val_loss: 0.5040\n",
            "Epoch 113/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9774 - loss: 0.0635 - val_accuracy: 0.7911 - val_loss: 0.9572\n",
            "Epoch 114/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9799 - loss: 0.0577 - val_accuracy: 0.6911 - val_loss: 1.9472\n",
            "Epoch 115/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9816 - loss: 0.0598 - val_accuracy: 0.8978 - val_loss: 0.3896\n",
            "Epoch 116/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9668 - loss: 0.0854 - val_accuracy: 0.7867 - val_loss: 1.1265\n",
            "Epoch 117/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9711 - loss: 0.0715 - val_accuracy: 0.9167 - val_loss: 0.2760\n",
            "Epoch 118/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9819 - loss: 0.0601 - val_accuracy: 0.3822 - val_loss: 10.2696\n",
            "Epoch 119/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9800 - loss: 0.0640 - val_accuracy: 0.9022 - val_loss: 0.3680\n",
            "Epoch 120/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1024 - val_accuracy: 0.9111 - val_loss: 0.3294\n",
            "Epoch 121/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.0743 - val_accuracy: 0.8589 - val_loss: 0.5311\n",
            "Epoch 122/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9652 - loss: 0.0782 - val_accuracy: 0.7967 - val_loss: 0.9543\n",
            "Epoch 123/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9752 - loss: 0.0683 - val_accuracy: 0.8389 - val_loss: 0.4866\n",
            "Epoch 124/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9779 - loss: 0.0571 - val_accuracy: 0.6822 - val_loss: 2.1550\n",
            "Epoch 125/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9818 - loss: 0.0545 - val_accuracy: 0.8600 - val_loss: 0.7175\n",
            "Epoch 126/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9802 - loss: 0.0577 - val_accuracy: 0.8211 - val_loss: 1.0758\n",
            "Epoch 127/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9751 - loss: 0.0696 - val_accuracy: 0.8944 - val_loss: 0.4616\n",
            "Epoch 128/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9825 - loss: 0.0455 - val_accuracy: 0.8289 - val_loss: 0.6901\n",
            "Epoch 129/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.0459 - val_accuracy: 0.8456 - val_loss: 0.8924\n",
            "Epoch 130/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9746 - loss: 0.1025 - val_accuracy: 0.8567 - val_loss: 0.4880\n",
            "Epoch 131/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9755 - loss: 0.0646 - val_accuracy: 0.8400 - val_loss: 1.1160\n",
            "Epoch 132/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9811 - loss: 0.0504 - val_accuracy: 0.8567 - val_loss: 0.7059\n",
            "Epoch 133/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.0742 - val_accuracy: 0.9144 - val_loss: 0.3193\n",
            "Epoch 134/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9829 - loss: 0.0513 - val_accuracy: 0.7456 - val_loss: 0.8274\n",
            "Epoch 135/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9762 - loss: 0.0732 - val_accuracy: 0.8189 - val_loss: 0.7814\n",
            "Epoch 136/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0590 - val_accuracy: 0.8156 - val_loss: 0.6380\n",
            "Epoch 137/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0382 - val_accuracy: 0.8122 - val_loss: 0.9905\n",
            "Epoch 138/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9802 - loss: 0.0427 - val_accuracy: 0.8533 - val_loss: 0.4961\n",
            "Epoch 139/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0355 - val_accuracy: 0.8989 - val_loss: 0.3579\n",
            "Epoch 140/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0614 - val_accuracy: 0.9200 - val_loss: 0.3213\n",
            "Epoch 141/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9753 - loss: 0.0673 - val_accuracy: 0.6967 - val_loss: 2.1944\n",
            "Epoch 142/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.0515 - val_accuracy: 0.9078 - val_loss: 0.4817\n",
            "Epoch 143/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9677 - loss: 0.0991 - val_accuracy: 0.7600 - val_loss: 1.5278\n",
            "Epoch 144/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9903 - loss: 0.0412 - val_accuracy: 0.8544 - val_loss: 0.4466\n",
            "Epoch 145/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 0.0319 - val_accuracy: 0.6111 - val_loss: 2.6511\n",
            "Epoch 146/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9819 - loss: 0.0528 - val_accuracy: 0.7900 - val_loss: 0.9859\n",
            "Epoch 147/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9816 - loss: 0.0520 - val_accuracy: 0.6089 - val_loss: 2.0145\n",
            "Epoch 148/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.0557 - val_accuracy: 0.8578 - val_loss: 0.5741\n",
            "Epoch 149/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0377 - val_accuracy: 0.9000 - val_loss: 0.4685\n",
            "Epoch 150/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9735 - loss: 0.0775 - val_accuracy: 0.8500 - val_loss: 0.7561\n",
            "Epoch 151/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.0956 - val_accuracy: 0.8400 - val_loss: 0.8794\n",
            "Epoch 152/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0394 - val_accuracy: 0.8822 - val_loss: 0.6236\n",
            "Epoch 153/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9815 - loss: 0.0430 - val_accuracy: 0.3722 - val_loss: 8.7364\n",
            "Epoch 154/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9756 - loss: 0.0523 - val_accuracy: 0.8611 - val_loss: 0.5345\n",
            "Epoch 155/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0421 - val_accuracy: 0.7156 - val_loss: 1.9322\n",
            "Epoch 156/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0183 - val_accuracy: 0.8478 - val_loss: 0.4574\n",
            "Epoch 157/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0368 - val_accuracy: 0.7044 - val_loss: 1.5882\n",
            "Epoch 158/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0451 - val_accuracy: 0.8411 - val_loss: 0.5409\n",
            "Epoch 159/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.0582 - val_accuracy: 0.8667 - val_loss: 0.6323\n",
            "Epoch 160/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0293 - val_accuracy: 0.4978 - val_loss: 5.8305\n",
            "Epoch 161/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9838 - loss: 0.0453 - val_accuracy: 0.8889 - val_loss: 0.4631\n",
            "Epoch 162/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.0356 - val_accuracy: 0.6967 - val_loss: 2.1408\n",
            "Epoch 163/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0527 - val_accuracy: 0.8278 - val_loss: 0.8936\n",
            "Epoch 164/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9853 - loss: 0.0404 - val_accuracy: 0.6333 - val_loss: 2.7874\n",
            "Epoch 165/1000\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0424 - val_accuracy: 0.7978 - val_loss: 1.1741\n"
          ]
        }
      ],
      "source": [
        "from keras import losses\n",
        "\n",
        "# Initialize the model using the build_model function that was previously defined\n",
        "estimator = build_model()\n",
        "\n",
        "# Compile the model:\n",
        "# - Loss function: categorical_crossentropy is used to measure the error between the predicted probability distribution and the true distribution for multi-class classification tasks.\n",
        "# - Optimizer: 'Adam' is used to minimize the loss function efficiently\n",
        "# - Metrics: Accuracy is used to track the model's performance during training\n",
        "estimator.compile(loss=keras.losses.categorical_crossentropy, optimizer = 'Adam', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback to prevent overfitting:\n",
        "# - monitor: monitor the validation accuracy during training\n",
        "# - patience: stop training if the validation accuracy doesn't improve for 100 consecutive epochs\n",
        "# - mode: 'max' indicates that training will stop when the validation accuracy reaches its maximum\n",
        "# - restore_best_weights: restore the weights from the best epoch (the one with the highest validation accuracy)\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, mode='max', restore_best_weights=True)\n",
        "\n",
        "# Custom callback to display training progress:\n",
        "# - Print a dot for every epoch (or newline every 100 epochs) to indicate progress in training\n",
        "class PrintD(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        if epoch % 100 == 0:  # Print a newline every 100 epochs\n",
        "            print('')\n",
        "        print('.', end='')  # Print a dot to indicate progress during each epoch\n",
        "\n",
        "# Set the maximum number of epochs (iterations over the entire dataset)\n",
        "EPOCHS = 1000\n",
        "\n",
        "# Train the model using the `fit` method:\n",
        "# - encoding_pad: The padded training data (inputs)\n",
        "# - Y: The target values (outputs)\n",
        "# - verbose: set to 1 to print progress during training\n",
        "# - epochs: The number of times to iterate over the entire dataset\n",
        "# - validation_split: the fraction of data to use for validation (used to monitor validation loss)\n",
        "# - batch_size: the number of samples per gradient update\n",
        "# - callbacks: list of callbacks to be used during training (early stopping and progress display)\n",
        "history = estimator.fit(encoding, Y, verbose=1, epochs=EPOCHS, validation_data=(encoding_valid, Y_valid), batch_size=32, callbacks=[early_stop, PrintD()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox4ZpuqOOK1j"
      },
      "source": [
        "### Evaluate the trained model\n",
        "We evaluate our classifier by using the test set, which was not seen by the network during training. We plot the results as a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "TSgTvf8TOK1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da265c06-2865-4caa-c712-1e2fff54a29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step\n",
            "[[93  6  1]\n",
            " [15 81  4]\n",
            " [ 5  1 94]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on test set\n",
        "predicted_test = np.array(estimator.predict(encoding_test))\n",
        "pred_cat = [i.argmax() for i in predicted_test]\n",
        "\n",
        "# Confusion matrix\n",
        "print(confusion_matrix(Y_test, pred_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 3: Confusion matrix\n",
        "\n",
        "**Question 3 (write the answer at the assessment form):** Examine the confusion matrix produced after evaluating the model on the test set. a) What does the confusion matrix reveal about the model’s performance? b) What indications in the matrix would suggest that the model is biased toward one particular class?"
      ],
      "metadata": {
        "id": "aJ4fAITLqhQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anwers:\n",
        "a) The confusion matrix reveals how well the model is performing by showing the number of correct and incorrect predictions for each class, allowing us to identify areas of strength and weakness in the model's predictions.  We observe that the model predicts more correct values (93 percent accuracy for BD,81 percent accuracy for BDEI, 94 percent accuracy for BDSS)\n",
        "\n",
        "b) Indications of bias toward one particular class include significantly higher values along the diagonal for that class compared to others (indicating more correct predictions) and lower values in the corresponding rows or columns for other classes, which may show a higher number of false positives or false negatives. for the case of our  model we can not say that our model is bias because the difference is not soo big."
      ],
      "metadata": {
        "id": "Dl6AIuhq4mTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can compare the obtained accuracy with other State of the Art approaches. :\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1mamPD_VCI74Y8LzhnHHNyLzfIFqZA8cO\" width=\"300\" height=\"500\">\n",
        "\n",
        "Note that we are using 1,000 trees per model for training, compared to 4 million trees of each model to train the FFNN-SS and CNN-CBLV of [Voznica et al. (2022)](https://www.nature.com/articles/s41467-022-31511-0#Sec29).\n",
        "\n"
      ],
      "metadata": {
        "id": "SjRS0Iv7VDzc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjuGpXvIOK1j"
      },
      "source": [
        "## 5. Predicting empirical (real) data.\n",
        "Our trained network can now be used to predict the most likely epidemiological model on real datasets.\n",
        "We will use the the phylogenetic tree from [Rasmusen et al. (2017)](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005448) with 200 HIV-1 sequences collected as part of the [Swiss Cohort Study (2010)](https://academic.oup.com/ije/article/39/5/1179/799735).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Fzc9naQ8ACbL9i6_ZDWh1o8GhIvJ1ql4\" width=\"500\" height=\"340\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "lU0UGNzcOK1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c64f0a-10db-453a-a1a4-5bf9b282c133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640ms/step\n",
            "  BD            BDEI          BDSS\n",
            "[[1.3270288e-25 1.0000000e+00 1.9609776e-22]]\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "encoding_Zurich = np.load('/content/PhyloDyn/Encoded_Zurich.npy')\n",
        "\n",
        "\n",
        "# predict values for the empirical dataset\n",
        "predicted_emp = np.array(estimator.predict(encoding_Zurich))\n",
        "\n",
        "# Print the results\n",
        "print(\"  BD            BDEI          BDSS\")\n",
        "print(predicted_emp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 4: Analysis of Empirical Data Predictions\n",
        "\n",
        "**Question 4 (write answer at the assessment form):** The trained model predicts epidemiological models for the HIV data (Zurich dataset). a) Which model was selected, and how does this compare to the results reported in the paper (BDSS with superspreaders)? b) If your prediction differs from BDSS, what factors might explain the discrepancy?"
      ],
      "metadata": {
        "id": "bSM5cu8bxkt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-g8R0SCs8-5K"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}