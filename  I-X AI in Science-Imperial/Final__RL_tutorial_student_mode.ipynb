{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MELAI-1/WORKSHOPS-AND-SCIENTIFIC-OUTREACH/blob/main/%20I-X%20AI%20in%20Science-Imperial/Final__RL_tutorial_student_mode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-ot2n2b9Egj"
      },
      "source": [
        "# Design Materials with optimal propertities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNaY7rA39Egm"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <b>Part 1: Background</b>\n",
        "  \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRflq2vq9Egn"
      },
      "source": [
        "<div style=\"display: flex; justify-content: center;\">\n",
        "    <iframe src=\"https://drive.google.com/file/d/152YDnfX35z1_jj8zwjhrKmfmoJgBRt3p/view?usp=sharing\" width=\"50%\" height=\"300px\"></iframe>\n",
        "</div>\n",
        "\n",
        "[Lecture slides](https://drive.google.com/file/d/152YDnfX35z1_jj8zwjhrKmfmoJgBRt3p/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH2m6gzz9Egn"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <b>Part 2: Hands on</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjFnzcivSpy2"
      },
      "source": [
        "### Hands on: Self-Driving Taxi with Reinforcement Tabular Q-Learning\n",
        "This tutorial is updated and based on [here](https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWNGYQ-mLe_W"
      },
      "outputs": [],
      "source": [
        "!pip install gym\n",
        "!pip install pygame\n",
        "!pip install cmake 'gym[atari]' scipy\n",
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18yMvmzuS6Ho"
      },
      "source": [
        "The Smartcab's job is to pick up the passenger at one location and drop them off in another. Here are a few things that we'd love our Smartcab to take care of:\n",
        "\n",
        "1. Drop off the passenger to the right location.\n",
        "2. Save passenger's time by taking minimum time possible to drop off\n",
        "3. Take care of passenger's safety and traffic rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-4LjF5WUw2Y"
      },
      "source": [
        "### A random start of state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijftl7wsMdyS"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the Taxi-v3 environment\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "\n",
        "env.reset()\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhiG4BrwU3R5"
      },
      "source": [
        "**Tips: Understanding the env.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0IUMCgRO8jJ",
        "outputId": "5130ee45-fe2e-4377-8c42-d54ba0789751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space Discrete(6)\n",
            "State Space Discrete(500)\n"
          ]
        }
      ],
      "source": [
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Babplv9NU86t"
      },
      "source": [
        "**1. Rewards**\n",
        "\n",
        "<div style=\\\"background-color: #f8d7da; border-left: 6px solid #ccc; margin: 20px; padding: 15px;\\\">\n",
        "    <strong>ðŸ’¡ What kind of rewards we need to design? </strong>\n",
        "</div>\n",
        "\n",
        "Since the agent (the imaginary driver) is reward-motivated and is going to learn how to control the cab by trial experiences in the environment, we need to decide the rewards and/or penalties and their magnitude accordingly.\n",
        "<details>\n",
        "<summary> <b>  Here a few points to consider ðŸ’¡: </b> </summary>\n",
        "i. The agent should receive a high positive reward for a successful dropoff because this behavior is highly desired\n",
        "\n",
        "ii. The agent should be penalized if it tries to drop off a passenger in wrong locations\n",
        "\n",
        "iii. The agent should get a slight negative reward for not making it to the destination after every time-step. \"Slight\" negative because we would prefer our agent to reach late instead of making wrong moves trying to reach to the destination as fast as possible\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFTm6CiAWY_h"
      },
      "source": [
        "**2. State Space**\n",
        "\n",
        "The State Space is the set of all possible situations our taxi could inhabit. The state should contain useful information the agent needs to make the right action.\n",
        "\n",
        "Let's say we have a training area for our Smartcab where we are teaching it to transport people in a parking lot to four different locations (R, G, Y, B).\n",
        "\n",
        "Let's assume Smartcab is the only vehicle in this parking lot. We can break up the parking lot into a 5x5 grid, which gives us 25 possible taxi locations. These 25 locations are one part of our state space. Notice the current location state of our taxi is coordinate (3, 1).\n",
        "\n",
        "You'll also notice there are four (4) locations that we can pick up and drop off a passenger: R, G, Y, B or [(0,0), (0,4), (4,0), (4,3)] in (row, col) coordinates. Our illustrated passenger is in location Y and they wish to go to location R.\n",
        "\n",
        "We also account for one (1) additional passenger state of being inside the taxi.\n",
        "<details>\n",
        "<summary> <b>  Calculate all the possible states of the taxi environment ðŸ’¡: </b> </summary>\n",
        "we can take all combinations of passenger locations and destination locations to come to a total number of states for our taxi environment; there's four (4) destinations and five (4 + 1) passenger locations.\n",
        "\n",
        "So, our taxi environment has  **5 * 5 * 5 * 4 = 500**\n",
        " total possible states.\n",
        "</details>\n",
        "\n",
        "Check if your calculation is correct. ðŸ˜¸\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2cyUtdlZeKM"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usRCj1gqb2zx"
      },
      "source": [
        "**3. Actions**\n",
        "\n",
        "The agent encounters one of the 500 states and it takes an action. The action in our case can be to move in a direction or decide to pickup/dropoff a passenger. In other words, we have six possible actions:\n",
        "\n",
        " **0-south, 1-north, 2-east, 3-west, 4-pickup, 5-dropoff**\n",
        "\n",
        "You'll notice in the illustration above, that the taxi cannot perform certain actions in **certain states due to walls**. In environment's code, we will simply provide a **-1** penalty for every wall hit and the taxi won't move anywhere. This will just rack up penalties causing the taxi to consider going around the wall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD-sSiHImcI5"
      },
      "source": [
        "Options: mannually set the state of the env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erbef2I6O-Xh",
        "outputId": "cbb2cfb8-cda1-4354-ea2a-c11ccd21eea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State: 348\n"
          ]
        }
      ],
      "source": [
        "state = env.encode(3, 2, 2, 0) # (taxi row, taxi column, passenger index, destination index)\n",
        "print(\"State:\", state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFIQIWc0mirH"
      },
      "source": [
        "<strong> Reward table of an env </strong>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7Bq94d0mxM3"
      },
      "source": [
        "We can think of it like a matrix that has the number of states as rows and number of actions as columns, i.e. a **states * actions** matrix.\n",
        "\n",
        "1. This dictionary has the structure **{action: [(probability, nextstate, reward, done)]}**.\n",
        "\n",
        "2. Note that if our agent chose to explore action two (2) in this state it would be going East into a wall. The source code has made it impossible to actually move the taxi across a wall, so if the taxi chooses that action, it will just keep accruing -1 penalties, which affects the long-term reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raF0ByYxPWur",
        "outputId": "d915b76a-8fea-469e-9ec3-3fe5c94eb191"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [(1.0, 428, -1, False)],\n",
              " 1: [(1.0, 228, -1, False)],\n",
              " 2: [(1.0, 348, -1, False)],\n",
              " 3: [(1.0, 328, -1, False)],\n",
              " 4: [(1.0, 328, -10, False)],\n",
              " 5: [(1.0, 328, -10, False)]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "env.P[328] #Transition dynamics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn_sFjq4PhSF"
      },
      "source": [
        "### Without RL just random search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l9FQ7xAPXwY"
      },
      "outputs": [],
      "source": [
        "env.s = 328  # set environment to illustration's state\n",
        "\n",
        "epochs = 0\n",
        "penalties, reward = 0, 0\n",
        "\n",
        "frames = [] # for animation\n",
        "\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    state, reward, done, truncated, info = env.step(action)\n",
        "\n",
        "    if reward == -10:\n",
        "        penalties += 1\n",
        "    frames.append({\n",
        "        'frame': env.render(),\n",
        "        'state': state,\n",
        "        'action': action,\n",
        "        'reward': reward\n",
        "        }\n",
        "    )\n",
        "    epochs += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-j4612cPsdP",
        "outputId": "dd1d8fc3-345f-425f-da65-320c177bd6ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timesteps taken: 1009\n",
            "Penalties incurred: 317\n"
          ]
        }
      ],
      "source": [
        "print(\"Timesteps taken: {}\".format(epochs))\n",
        "print(\"Penalties incurred: {}\".format(penalties))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAB3s5tQpunh"
      },
      "source": [
        "### With Reinforcement learning, we use Q-learning here\n",
        "\n",
        "**Q-learning**\n",
        "\n",
        "The values store in the Q-table are called a Q-values, and they map to a (state, action) combination.\n",
        "\n",
        "If the taxi is faced with a state that includes a passenger at its current location, it is highly likely that the Q-value for **pickup** is higher when compared to other actions, like dropoff or north.\n",
        "\n",
        "Q-values are initialized to an arbitrary value, and as the agent exposes itself to the environment and receives different rewards by executing different actions, the Q-values are updated using the equation:\n",
        "\n",
        "**Q(state, action) = (1-alpha)Q(state, action) + alpha * (reward + gamma * (max) Q(nextstate, all actions)**\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "-\n",
        " (alpha) is the learning rate (0 < alpha <= 1)\n",
        ") - Just like in supervised learning settings,\n",
        " is the extent to which our Q-values are being updated in every iteration.\n",
        "\n",
        "-\n",
        " (gamma) is the discount factor (0 <= gamma <= 1\n",
        ") - determines how much importance we want to give to future rewards. A high value for the discount factor (close to 1) captures the long-term effective award, whereas, a discount factor of 0 makes our agent consider only immediate reward, hence making it greedy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7aa4p0awCcs"
      },
      "source": [
        "**Q-Table**\n",
        "\n",
        "The Q-table is a matrix where we have a row for every state (500) and a column for every action (6). It's first initialized to 0, and then values are updated after training. Note that the Q-table has the same dimensions as the reward table, but it has a completely different purpose.\n",
        "\n",
        "Breaking it down into steps, we get\n",
        "\n",
        "1. Initialize the Q-table by all zeros.\n",
        "2. Start exploring actions: For each state, select any one among all possible actions for the current state (S).\n",
        "3. Travel to the next state (S') as a result of that action (a).\n",
        "4. For all possible actions from the state (S') select the one with the highest Q-value.\n",
        "5. Update Q-table values using the equation.\n",
        "6. Set the next state as the current state.\n",
        "\n",
        "If goal state is reached, then end and repeat the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxDe6UY4xABs",
        "outputId": "3fc8a7ce-7054-43e3-f7ed-1973de277ddb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "q_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJMUEOzQwsHD"
      },
      "source": [
        "Exploiting learned values\n",
        "\n",
        "After enough random exploration of actions, the Q-values tend to converge serving our agent as an action-value function which it can exploit to pick the most optimal action from a given state.\n",
        "\n",
        "There's a tradeoff between exploration (choosing a random action) and exploitation (choosing actions based on already learned Q-values). We want to prevent the action from always taking the same route, and possibly overfitting, so we'll be introducing another parameter called\n",
        " **\"epsilon\"** to cater to this during training.\n",
        "\n",
        "Instead of just selecting the best learned Q-value action, we'll sometimes favor exploring the action space further. Lower epsilon value results in episodes with more penalties (on average) which is obvious because we are exploring and making random decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0NnC-6txGom"
      },
      "source": [
        "### **Implementing Q-learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwB3xXkqykYx"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I define the function which will return the best action after training"
      ],
      "metadata": {
        "id": "rqYEfGG0zt3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_action(q_table, state):\n",
        "    \"\"\"\n",
        "    Determines the best action for a given state based on Q-table values\n",
        "\n",
        "    Parameters:\n",
        "    - q_table: The Q-table containing action values\n",
        "    - state: The current state index\n",
        "\n",
        "    Returns:\n",
        "    - best_action: The action with the highest Q-value\n",
        "    - max_value: The corresponding maximum Q-value\n",
        "    \"\"\"\n",
        "    # Extract action values for the given state\n",
        "    action_values = q_table[state]\n",
        "\n",
        "    # Find the max value and its index using NumPy's argmax\n",
        "    best_action = np.argmax(action_values) # Changed this line to use np.argmax\n",
        "    max_value = action_values[best_action]\n",
        "\n",
        "    # Mapping actions to their meanings\n",
        "    action_meanings = {\n",
        "        0: 'South',\n",
        "        1: 'North',\n",
        "        2: 'East',\n",
        "        3: 'West',\n",
        "        4: 'Pickup',\n",
        "        5: 'Dropoff'\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'best_action': best_action,\n",
        "        'best_action_meaning': action_meanings[best_action],\n",
        "        'max_value': max_value\n",
        "    }\n"
      ],
      "metadata": {
        "id": "57HCADeny3WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdrzUtUtP1ZB",
        "outputId": "be2ce45f-58d9-4db6-fb4c-4d61748d98bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Initialize the Taxi-v3 environment\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")  # Render as RGB images\n",
        "\n",
        "# Define hyperparameters\n",
        "alpha = 0.1       # Learning rate\n",
        "gamma = 0.99      # Discount factor\n",
        "epsilon = 1.0     # Exploration rate\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.01\n",
        "episodes = 100\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "# Initialize Q-table\n",
        "state_space_size = env.observation_space.n\n",
        "action_space_size = env.action_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    #total_reward = 0\n",
        "    for step in range(max_steps_per_episode):\n",
        "        #frame = env.render()  # Render the environment as an RGB array\n",
        "        #frames.append(Image.fromarray(frame))  # Convert frame to an image\n",
        "        action = np.argmax(q_table[state])\n",
        "        ## the way to use epsilon\n",
        "        # if np.random.rand() < epsilon:\n",
        "        #     action = np.random.choice(action_space_size)  # Explore\n",
        "        # else:\n",
        "        #     action = np.argmax(q_table[state])  # Exploit\n",
        "\n",
        "        # Perform the action\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (\n",
        "            reward + gamma * np.max(q_table[next_state]) - q_table[state, action]\n",
        "        )\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay) #did you notice that the epsilon is not used here? how to modify?\n",
        "\n",
        "\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# # Save frames as a GIF wit:h infinite looping\n",
        "# gif_path = \"taxi_v3_simulation.gif\"\n",
        "# frames[0].save(\n",
        "#     gif_path, save_all=True, append_images=frames[1:], duration=300, loop=0\n",
        "# )\n",
        "# print(f\"GIF saved at {gif_path}\")\n",
        "\n",
        "# # Display the GIF in the notebook with infinite looping\n",
        "# from IPython.display import HTML\n",
        "# display(HTML(f'<img src=\"{gif_path}\" style=\"display:block;\">'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_100 = get_best_action(q_table, 328)\n",
        "print(f\"Best Action: {result_100['best_action_meaning']} (Index: {result_100['best_action']})\")\n",
        "print(f\"Max Q-Value: {result_100['max_value']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QxWTjQqz-SU",
        "outputId": "fcc88aed-3505-448e-a058-940d2e2aeda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Action: South (Index: 0)\n",
            "Max Q-Value: -0.5847967256005999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answers: Go for \"**West**\" if we train the q-table with 100 episodes."
      ],
      "metadata": {
        "id": "79YfIOHE0UEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Taxi-v3 environment\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")  # Render as RGB images\n",
        "\n",
        "# Define hyperparameters\n",
        "alpha = 0.1       # Learning rate\n",
        "gamma = 0.99      # Discount factor\n",
        "epsilon = 1.0     # Exploration rate\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.01\n",
        "episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "# Initialize Q-table\n",
        "state_space_size = env.observation_space.n\n",
        "action_space_size = env.action_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    #total_reward = 0\n",
        "    for step in range(max_steps_per_episode):\n",
        "        #frame = env.render()  # Render the environment as an RGB array\n",
        "        #frames.append(Image.fromarray(frame))  # Convert frame to an image\n",
        "        action = np.argmax(q_table[state])\n",
        "        ## the way to use epsilon\n",
        "        # if np.random.rand() < epsilon:\n",
        "        #     action = np.random.choice(action_space_size)  # Explore\n",
        "        # else:\n",
        "        #     action = np.argmax(q_table[state])  # Exploit\n",
        "\n",
        "        # Perform the action\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (\n",
        "            reward + gamma * np.max(q_table[next_state]) - q_table[state, action]\n",
        "        )\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay) #did you notice that the epsilon is not used here? how to modify?\n",
        "\n",
        "\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# # Save frames as a GIF wit:h infinite looping\n",
        "# gif_path = \"taxi_v3_simulation.gif\"\n",
        "# frames[0].save(\n",
        "#     gif_path, save_all=True, append_images=frames[1:], duration=300, loop=0\n",
        "# )\n",
        "# print(f\"GIF saved at {gif_path}\")\n",
        "\n",
        "# # Display the GIF in the notebook with infinite looping\n",
        "# from IPython.display import HTML\n",
        "# display(HTML(f'<img src=\"{gif_path}\" style=\"display:block;\">'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REJYzutM0NBa",
        "outputId": "344c7718-d4de-4cca-9be8-a1a67f875c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_1000 = get_best_action(q_table, 328)\n",
        "print(f\"Best Action: {result_1000['best_action_meaning']} (Index: {result_1000['best_action']})\")\n",
        "print(f\"Max Q-Value: {result_1000['max_value']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzGKnpft1DhR",
        "outputId": "017c9d7a-3a94-4d61-a7e3-e1d628bbf1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Action: North (Index: 1)\n",
            "Max Q-Value: -3.8649205630816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-RQrzlw0zJq"
      },
      "source": [
        "Answers: Go for \"**North**\" if we train the q-table with 1000 episodes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Taxi-v3 environment\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")  # Render as RGB images\n",
        "\n",
        "# Define hyperparameters\n",
        "alpha = 0.1       # Learning rate\n",
        "gamma = 0.99      # Discount factor\n",
        "epsilon = 1.0     # Exploration rate\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.01\n",
        "episodes = 5000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "# Initialize Q-table\n",
        "state_space_size = env.observation_space.n\n",
        "action_space_size = env.action_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    #total_reward = 0\n",
        "    for step in range(max_steps_per_episode):\n",
        "        #frame = env.render()  # Render the environment as an RGB array\n",
        "        #frames.append(Image.fromarray(frame))  # Convert frame to an image\n",
        "        action = np.argmax(q_table[state])\n",
        "        ## the way to use epsilon\n",
        "        # if np.random.rand() < epsilon:\n",
        "        #     action = np.random.choice(action_space_size)  # Explore\n",
        "        # else:\n",
        "        #     action = np.argmax(q_table[state])  # Exploit\n",
        "\n",
        "        # Perform the action\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (\n",
        "            reward + gamma * np.max(q_table[next_state]) - q_table[state, action]\n",
        "        )\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay) #did you notice that the epsilon is not used here? how to modify?\n",
        "\n",
        "\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# # Save frames as a GIF wit:h infinite looping\n",
        "# gif_path = \"taxi_v3_simulation.gif\"\n",
        "# frames[0].save(\n",
        "#     gif_path, save_all=True, append_images=frames[1:], duration=300, loop=0\n",
        "# )\n",
        "# print(f\"GIF saved at {gif_path}\")\n",
        "\n",
        "# # Display the GIF in the notebook with infinite looping\n",
        "# from IPython.display import HTML\n",
        "# display(HTML(f'<img src=\"{gif_path}\" style=\"display:block;\">'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW5z-Qts1rgQ",
        "outputId": "195e3c8e-b7e1-472f-af5d-e2fe3143c5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_5000 = get_best_action(q_table, 328)\n",
        "print(f\"Best Action: {result_5000['best_action_meaning']} (Index: {result_5000['best_action']})\")\n",
        "print(f\"Max Q-Value: {result_5000['max_value']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJoaReFj1v70",
        "outputId": "321b6433-a2b7-4818-8465-f210f0ebf82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Action: North (Index: 1)\n",
            "Max Q-Value: 8.6980411914447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answers: Go for \"**North**\" if we train the q-table with 5000 episodes."
      ],
      "metadata": {
        "id": "8kf0MP8w2Sc8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9S-x1iUyofl"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6MNuoz4yiz3"
      },
      "outputs": [],
      "source": [
        "# Testing the trained agent and rendering as GIF\n",
        "frames = []  # Store frames for GIF\n",
        "test_episodes = 1\n",
        "for episode in range(test_episodes):\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps_per_episode):\n",
        "        frame = env.render()  # Render the environment as an RGB array\n",
        "        frames.append(Image.fromarray(frame))  # Convert frame to an image\n",
        "        action = np.argmax(q_table[state])\n",
        "\n",
        "        # Correctly unpack the result of env.step()\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        done = done or truncated  # Handle termination\n",
        "        ## what is different between training and testing?\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "print(f\"Total reward per episode: {total_reward / test_episodes}\")\n",
        "\n",
        "env.close()\n",
        "\n",
        "# Save frames as a GIF\n",
        "gif_path = \"taxi_v3_simulation.gif\"\n",
        "frames[0].save(gif_path, save_all=True, append_images=frames[1:], duration=300, loop=0)\n",
        "print(f\"GIF saved at {gif_path}\")\n",
        "\n",
        "\n",
        "# Display the GIF in the notebook\n",
        "from IPython.display import Image as IPImage\n",
        "display(IPImage(gif_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j1vZyO-9Egz"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <b>Part 2.1: Homework</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4I6zsqY1AWW"
      },
      "source": [
        "### Reflection and improvement\n",
        "Requirements on homework: finish the task and import the notebook as a **pdf** with your codes, plots, results and discussions.\n",
        "#### Task 1: **Hyperparameters and optimizations**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we see and we know to optimize our q-learning we can â‰\n",
        "\n",
        "\n",
        "\n",
        "*   Try exploration during our strategies and for that we can  use **Epsilon-Greedy Decay**\n",
        "*   Hyperparameter Tuning\n",
        "* and sometimes also improve the strategy\n",
        "\n"
      ],
      "metadata": {
        "id": "Kj7NahTG2hti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "from PIL import Image\n",
        "import os\n",
        "import tqdm as tqdm\n",
        "\n",
        "# Initialize the Taxi-v3 environment\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "\n",
        "# Define hyperparameters\n",
        "alpha = 0.1       # Learning rate\n",
        "gamma = 0.99      # Discount factor\n",
        "epsilon = 1.0     # Exploration rate\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.01\n",
        "episodes = 5000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "# Initialize Q-table\n",
        "state_space_size = env.observation_space.n\n",
        "action_space_size = env.action_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "\n",
        "# Track rewards for evaluation\n",
        "rewards_per_episode = []\n",
        "\n",
        "# Training loop\n",
        "for episode in tqdm.tqdm(range(episodes)):\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "#epsilon-greedy algorithm\n",
        "    for step in range(max_steps_per_episode):\n",
        "        # Epsilon-greedy action selection\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = env.action_space.sample()  # Explore\n",
        "        else:\n",
        "            action = np.argmax(q_table[state])  # Exploit\n",
        "\n",
        "        # Perform the action\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "        # Update Q-table using Q-learning formula\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (\n",
        "            reward + gamma * np.max(q_table[next_state]) - q_table[state, action]\n",
        "        )\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        if done or truncated:\n",
        "            break\n",
        "\n",
        "    # Decay epsilon\n",
        "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "\n",
        "    # Track progress\n",
        "    rewards_per_episode.append(total_reward)\n",
        "\n",
        "    # Print progress every 100 episodes\n",
        "    if (episode + 1) % 100 == 0:\n",
        "        avg_reward = np.mean(rewards_per_episode[-100:])\n",
        "        print(f\"Episode: {episode+1}, Average Reward (last 100): {avg_reward:.2f}, Epsilon: {epsilon:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "id": "gVoIYe9nsMjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training progress\n",
        "plt.figure(figsize=(10, 5))\n",
        "window_size = 100\n",
        "avg_rewards = [np.mean(rewards_per_episode[max(0, i-window_size):i+1])\n",
        "               for i in range(len(rewards_per_episode))]\n",
        "plt.plot(rewards_per_episode, alpha=0.5, label='Rewards')\n",
        "plt.plot(avg_rewards, label=f'Average Reward (window={window_size})')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ntI_DwSV8HWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to evaluate the trained agent\n",
        "def evaluate_agent(env, q_table, num_episodes=10, render=False):\n",
        "    total_rewards = []\n",
        "    frames = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()[0]\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            if render and episode == 0:  # Only render the first episode\n",
        "                frames.append(Image.fromarray(env.render()))\n",
        "\n",
        "            # Always choose the best action\n",
        "            action = np.argmax(q_table[state])\n",
        "            next_state, reward, done, truncated, info = env.step(action)\n",
        "            episode_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "            if done or truncated:\n",
        "                break\n",
        "\n",
        "        total_rewards.append(episode_reward)\n",
        "\n",
        "    # Save the first episode as a GIF if rendering was enabled\n",
        "    if render and frames:\n",
        "        gif_path = \"taxi_v3_solution.gif\"\n",
        "        frames[0].save(\n",
        "            gif_path, save_all=True, append_images=frames[1:], duration=300, loop=0\n",
        "        )\n",
        "        # print(f\"GIF saved at {gif_path}\")\n",
        "        # display(HTML(f'<img src=\"{gif_path}\" style=\"display:block;\">'))\n",
        "\n",
        "    return np.mean(total_rewards)\n",
        "\n",
        "# Evaluate the trained agent\n",
        "avg_reward = evaluate_agent(env, q_table, num_episodes=10, render=True)\n",
        "print(f\"Average reward over 10 evaluation episodes: {avg_reward}\")\n",
        "\n",
        "# Close the environment\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUigiIyMzEZi",
        "outputId": "dcead354-2621-4269-ff8f-8a9c3bba2865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward over 10 evaluation episodes: 8.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the agent\n",
        "# Testing the trained agent and rendering as GIF\n",
        "frames = []  # Store frames for GIF\n",
        "test_episodes = 1\n",
        "for episode in range(test_episodes):\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps_per_episode):\n",
        "        frame = env.render()  # Render the environment as an RGB array\n",
        "        frames.append(Image.fromarray(frame))  # Convert frame to an image\n",
        "        action = np.argmax(q_table[state])\n",
        "\n",
        "        # Correctly unpack the result of env.step()\n",
        "        next_state, reward, done, truncated, info = env.step(action)\n",
        "        done = done or truncated  # Handle termination\n",
        "        ## what is different between training and testing?\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "print(f\"Total reward per episode: {total_reward / test_episodes}\")\n",
        "\n",
        "env.close()\n",
        "\n",
        "# Save frames as a GIF\n",
        "gif_path = \"taxi_v3_simulation.gif\"\n",
        "frames[0].save(gif_path, save_all=True, append_images=frames[1:], duration=300, loop=0)\n",
        "print(f\"GIF saved at {gif_path}\")\n",
        "\n",
        "\n",
        "# Display the GIF in the notebook\n",
        "from IPython.display import Image as IPImage\n",
        "display(IPImage(gif_path))\n"
      ],
      "metadata": {
        "id": "gDLQAHIJsdjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comments:**\n",
        "\n",
        "In this part I tried:\n",
        "\n",
        "\n",
        "*   different space of parameters\n",
        "*   define the number of step after no change we can break\n",
        "\n"
      ],
      "metadata": {
        "id": "EE9MB0jPpX0V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAY_WWD69EhK"
      },
      "source": [
        "#### Task 2: **Which field you think also used this Q learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-Learning has revolutionized :\n",
        "\n",
        "*  **Robotic navigation and autonomous systems** that enable machines to learn optimal decision-making strategies through trial and error. In robotics, algorithms can help robots learn complex movement patterns, obstacle avoidance, and efficient path planning by continuously updating their understanding of environmental interactions.\n",
        "\n",
        "* **has transformed algorithmic trading** by enabling systems to develop sophisticated investment strategies. These learning agents can analyze market conditions, predict potential outcomes, and make dynamic trading decisions by learning from historical data and adapting to changing market environments, potentially outperforming traditional rule-based trading methods.\n",
        "\n",
        "* **Autonomous vehicles** represent another critical domain where Q-Learning demonstrates immense potential. By learning from countless simulated and real-world driving scenarios, these intelligent systems can develop nuanced decision-making capabilities, improving navigation, predicting potential hazards, and making split-second choices that prioritize passenger safety and efficient route optimization.\n",
        "\n",
        "* **Healthcare applications of Q-Learning**are emerging as powerful tools for personalized medicine and treatment optimization. Machine learning models can analyze patient data, learn from treatment outcomes, and suggest personalized intervention strategies, potentially identifying optimal treatment paths that might not be immediately apparent to human practitioners.\n",
        "\n",
        "Importantly, when faced with a problem that can be modeled as a sequential decision-making process with discrete states and actions, Q-Learning emerges as the most intuitive and foundational algorithmic approach. Its core strength lies in its simplicity and ability to learn optimal strategies through iterative exploration and exploitation, making it the default baseline algorithm for reinforcement learning problems where an agent must learn to make a sequence of decisions in an uncertain environment."
      ],
      "metadata": {
        "id": "vzcKTETE9KX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "  <b>Part 3: Applying reinforcement learning in materials research</b>\n",
        "</div>"
      ],
      "metadata": {
        "id": "wBwQK_Trw4XV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVJSmTnI9EhL"
      },
      "source": [
        "#### Task elaboration:\n",
        "Now change the agent to a thermoelectric material Bi2Te3 (taxi here), you can download the structure from [here](https://next-gen.materialsproject.org/materials/mp-541837?formula=Bi2Se3); you have the options to change Te into Se and/or S.\n",
        "\n",
        "1. reward is the predicted zT value\n",
        "2. we use the 0.1 incrementally, therefore we have the choice that Te âˆˆ [0, 1], Se âˆˆ [0, 1], and S âˆˆ [0, 1], and the constraint that Te + Se + S = 1\n",
        "3. Therefore we have 10 * 10 * 10 (3D grid) options with some options that are not valid.\n",
        "4. the anion sites can choose to increase or decrease by a 0.1 step. Te-increase, Te-decrease, Se-increase, Se-decrese, S-increase, S-decrease\n",
        "5. the destination is when the composition with maximal zT is reached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37pnXYU99EhL"
      },
      "outputs": [],
      "source": [
        "# Installation of libraries\n",
        "!pip install optimade --quiet\n",
        "!pip install matminer --quiet\n",
        "!pip install elementembeddings --quiet\n",
        "!pip install pymatviz --quiet\n",
        "!pip install plotly --quiet\n",
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Ot7UEx9EhL"
      },
      "source": [
        "Database queries: Chemical space of thermoelectric materials\n",
        "We can use [matminer](https://matminer.readthedocs.io/en/latest/) to access a dataset. Today we will turn to thermoelectric materials.\n",
        "\n",
        "Thermoelectric devices convert temperature differences directly into electrical voltage, enabling applications in power generation and refrigeration. Their efficiency is characterised by the dimensionless figure of merit (zT), which depends on electrical conductivity, Seebeck coefficient, and thermal conductivity (read more here). Let's explore the diverse compositions that give rise to these properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZzgtXuX9EhL"
      },
      "outputs": [],
      "source": [
        "## code hint\n",
        "import matminer  # Materials informatics\n",
        "from matminer.datasets.dataset_retrieval import load_dataset  # Load materals datasets\n",
        "\n",
        "print(matminer.datasets.dataset_retrieval.get_all_dataset_info('ucsb_thermoelectrics'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#process the dataset into dataframe\n",
        "# Use matminer to download the dataset\n",
        "df = load_dataset('ucsb_thermoelectrics')\n",
        "\n",
        "print(f'The full dataset contains {df.shape[0]} entries. \\n')\n",
        "print('The DataFrame is shown below:')\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "gVbA635iDHC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the columns of the dataset\n",
        "print(\"Columns in the dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Check for any missing values in the dataset\n",
        "print(\"\\nChecking for missing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "fTuG8g0KD0G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot the distribution of zT values\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.histplot(df['zT'], bins=20, kde=True)\n",
        "plt.title('Thermoelectric figure of merit (zT)')\n",
        "plt.xlabel('zT (unitless)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D4uem5BzD_Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v38oYJ8R9EhL"
      },
      "source": [
        "For featurisation, we recommend using the [elementembeddings](https://wmd-group.github.io/ElementEmbeddings/stable/) library."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use matminer to featurise the dataset\n",
        "from matminer.featurizers.composition.composite import ElementProperty\n",
        "from pymatgen.core import Composition\n",
        "df2 = df.copy()\n",
        "df2['composition'] = df2.composition.apply(lambda x: Composition(x))\n",
        "\n",
        "# Create the ElementProperty featuriser\n",
        "el_prop_featuriser = ElementProperty.from_preset(preset_name='magpie')\n",
        "\n",
        "# By default multiprocessing is enabled, however, this can slow performance, so we disable it\n",
        "el_prop_featuriser.set_n_jobs(1)\n",
        "\n",
        "# Featurise using the ElementProperty featuriser\n",
        "df2 = el_prop_featuriser.featurize_dataframe(df2, col_id='composition')\n",
        "\n",
        "# Print the shape of the DataFrame\n",
        "print(df2.shape)\n",
        "df2.head()\n"
      ],
      "metadata": {
        "id": "PUUY0l6GFfHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the feature columns (excluding the first three)\n",
        "feature_columns = df2.columns[12:]\n",
        "\n",
        "# Create a unique colour for each feature\n",
        "colors = [plt.cm.jet(i / float(len(feature_columns))) for i in range(len(feature_columns))]\n",
        "\n",
        "# Plot the distribution of feature values with different colours\n",
        "plt.figure(figsize=(5, 4))\n",
        "for i, column in enumerate(feature_columns):\n",
        "    df2[column].plot(kind='hist', bins=10, alpha=0.5, color=colors[i], label=column)\n",
        "\n",
        "plt.title('Feature Distributions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qkKYCvU_F7j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MinMaxScaler is a data scaling technique to transform numerical features within the range [0, 1]. It linearly scales data, preserving relationships between values, making it suitable for algorithms sensitive to feature magnitudes.\n"
      ],
      "metadata": {
        "id": "UdoYJrehGhRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaled_df = df2.copy()\n",
        "\n",
        "# Step 1: Standardise the feature columns\n",
        "scaler = MinMaxScaler()\n",
        "scaled_df[feature_columns] = scaler.fit_transform(scaled_df[feature_columns])\n",
        "\n",
        "# Step 2: Plot the standardised feature distributions\n",
        "plt.figure(figsize=(5, 4))\n",
        "for column in feature_columns:\n",
        "    scaled_df[column].plot(kind='hist', bins=20, alpha=0.5, label=column)\n",
        "\n",
        "plt.title('Standardised Feature Distributions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "39fMhLIwGe11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's prepare the data for model training. We need to split the dataset into the target variable zT and the input features. For the input features, we must remove any non-numerical data to avoid getting errors later in our workflow.\n"
      ],
      "metadata": {
        "id": "FeOiNdW6ILXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.dropna()\n",
        "# Define the features we want\n",
        "features_to_drop = ['composition', 'crystallinity', 'synthesis', 'spacegroup',\n",
        "       'rho (ohm.cm)', 'S [muV/K]', 'PF [W/mK^2]', 'zT', 'kappa [W/mK]',\n",
        "       'sigma [S/cm]', 'T [K]', 'src']\n",
        "feature_cols = [col for col in list(df2.columns) if col not in features_to_drop]\n",
        "\n",
        "# Get an array of the features\n",
        "X = df2[feature_cols].values\n",
        "scaled_X = scaled_df[feature_cols].values\n",
        "\n",
        "# Get an array of the target variable\n",
        "y = df2['zT'].values\n",
        "\n",
        "print(f'Shape of X: {X.shape}')\n",
        "print(f'Shape of y: {y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBjOVe5mIKXt",
        "outputId": "19585fec-034c-4643-9950-2a4df547305c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (690, 132)\n",
            "Shape of y: (690,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model choice\n",
        "\n",
        "We are dealing with a supervised regression problem, so should choose a suitable machine learning model. We can start by rebuilding a random forest. Are you curious if the feature scaling has an effect? I am.\n"
      ],
      "metadata": {
        "id": "aJpX11gQIjOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest - original features\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "rf = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=3, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rf.fit(X,y)\n",
        "\n",
        "# Wrap the lines of code for later sections\n",
        "def make_prediction_plot(X, y, model, label):\n",
        "    y_pred = rf.predict(X)  # Calculate predictions here\n",
        "    fig, ax = plt.subplots(figsize=(5, 4))\n",
        "    ax.scatter(y, y_pred, c=y, cmap='viridis')\n",
        "    ax.plot(y, y, 'r-')\n",
        "    ax.set_xlabel(f'{label} True')\n",
        "    ax.set_ylabel(f'{label} Predicted')\n",
        "    plt.show()\n",
        "    return y_pred  # Return y_pred\n",
        "\n",
        "# Performance\n",
        "y_pred = make_prediction_plot(X, y, rf, 'zT')\n",
        "\n",
        "print(f'The training MAE = {metrics.mean_absolute_error(y,y_pred):.3f} ')\n",
        "print(f'The training RMSE = {np.sqrt(metrics.mean_squared_error(y,y_pred)):.3f}')\n",
        "print(f'The training r^2 = {rf.score(X,y):.3f}')"
      ],
      "metadata": {
        "id": "sXDpmvmzzUbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7snUcZLX9EhM"
      },
      "source": [
        "Now build your material env using gym\n",
        "* action space: we only care about the compositional ratio of Te:Se from 0 to 1 with a step of 0.01\n",
        "* reward function: you need to train a surrogate model based on the known database you have downloaded.\n",
        "* train the RL model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## featurize the composition of our target\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pymatgen.core import Composition\n",
        "\n",
        "def generate_random_Bi2Te3_substitution():\n",
        "    # Discretize the range 0 to 3 in steps of 0.1\n",
        "    increments = np.arange(0, 3.01, 0.3)\n",
        "\n",
        "    # Generate all valid (Te, Se) pairs, compute S = 3 - Te - Se\n",
        "    valid_combinations = []\n",
        "    for te in increments:\n",
        "        for se in increments:\n",
        "            s = 3.0 - te - se\n",
        "            if 0 <= s <= 3 and np.isclose(s % 0.3, 0, atol=1e-8):\n",
        "                valid_combinations.append((round(te, 1), round(se, 1), round(s, 1)))\n",
        "\n",
        "    # Choose one random combination\n",
        "    te_amt, se_amt, s_amt = valid_combinations[np.random.randint(len(valid_combinations))]\n",
        "\n",
        "    # Construct full composition including 0s\n",
        "    comp_dict = {\n",
        "        \"Bi\": 2,\n",
        "        \"Te\": te_amt,\n",
        "        \"Se\": se_amt,\n",
        "        \"S\": s_amt\n",
        "    }\n",
        "\n",
        "    # Create and return the Composition object\n",
        "    comp = Composition(comp_dict)\n",
        "    return comp\n",
        "\n",
        "# Generate 3 compositions\n",
        "compositions = [generate_random_Bi2Te3_substitution() for _ in range(3)]\n",
        "\n",
        "# Store in a DataFrame\n",
        "df_alloy = pd.DataFrame({\n",
        "    \"composition\": [comp for comp in compositions]\n",
        "})\n",
        "\n",
        "print(df_alloy)\n",
        "df_alloy = el_prop_featuriser.featurize_dataframe(df_alloy, col_id='composition')"
      ],
      "metadata": {
        "id": "ZWQjNaGKJ5ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_to_drop = ['composition', 'crystallinity', 'synthesis', 'spacegroup',\n",
        "       'rho (ohm.cm)', 'S [muV/K]', 'PF [W/mK^2]', 'zT', 'kappa [W/mK]',\n",
        "       'sigma [S/cm]', 'T [K]', 'src']\n",
        "feature_cols = [col for col in list(df_alloy.columns) if col not in features_to_drop]\n",
        "\n",
        "# Get an array of the features\n",
        "X = df_alloy[feature_cols].values\n",
        "\n",
        "reward_example = rf.predict(X)\n",
        "print(reward_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A00LekwKUWB",
        "outputId": "b0b4bbab-cebc-4e7f-fd31-ab2d289a0b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.58638093 0.4799631  0.52602026]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##start the RL part"
      ],
      "metadata": {
        "id": "4GZDXctjQjCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually for this 3D env, we are going to use it for the alloy chemical space, for the alloy, instead of having a 0.1 step, we now have 0.3, and so we have 11 * 11 *11 states or grid size. The reward is the predicted zT values of a composition. For the actions space, for each state, like the taxi, the alloy composition can choose to drop 0.3 Te or increase 0.3 Te, similarly for Se or S. Therefore have 6 actions. We don't have to do pickup, and dropoff, instead we need to find the composition with the highest zT values. the zT values can be calculated with a given function like function(composition). I hope for every given random starting point, the agent can quickly go to the optimal point of composition within a short trajectory.\n",
        "\n",
        "State = (Te_idx, Se_idx, S_idx); each index âˆˆ [0, 10]\n",
        "\n",
        "Action space = 6 actions:\n",
        "\n",
        "0: Te +0.3 (if Te < 3.0)\n",
        "\n",
        "1: Te -0.3 (if Te > 0)\n",
        "\n",
        "2: Se +0.3\n",
        "\n",
        "3: Se -0.3\n",
        "\n",
        "4: S +0.3\n",
        "\n",
        "5: S -0.3"
      ],
      "metadata": {
        "id": "8mUWUh8MTPEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymatgen.core import Composition\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "class AlloyCompositionEnv(gym.Env):\n",
        "    def __init__(self, zt_func, max_steps=20):\n",
        "        super().__init__()\n",
        "        self.grid_size = 1331 ## change to the correct value\n",
        "        self.step_size = 0.3 ## change to the correct value\n",
        "        self.max_index = self.grid_size - 1\n",
        "        self.zt_func = zt_func\n",
        "        self.max_steps = max_steps\n",
        "        self.current_step = 0\n",
        "\n",
        "        self.observation_space = spaces.MultiDiscrete([self.grid_size] * 3)\n",
        "        self.action_space = spaces.Discrete(6)\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        while True:\n",
        "            self.state = np.random.randint(0, self.grid_size, size=3)\n",
        "            if abs(sum(self.state) * self.step_size - 3.0) < 0.01:\n",
        "                break\n",
        "        self.current_step = 0\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return tuple(self.state)\n",
        "\n",
        "    def _state_to_composition(self, state):\n",
        "        te, se, s = state * self.step_size\n",
        "        composition_dict = {\"Bi\": 2}\n",
        "        if te > 0: composition_dict[\"Te\"] = round(te, 2)\n",
        "        if se > 0: composition_dict[\"Se\"] = round(se, 2)\n",
        "        if s > 0:  composition_dict[\"S\"] = round(s, 2)\n",
        "        return Composition(composition_dict)\n",
        "\n",
        "    def step(self, action):\n",
        "        delta = [0, 0, 0]\n",
        "        idx = action // 2\n",
        "        sign = 1 if action % 2 == 0 else -1\n",
        "        delta[idx] = sign\n",
        "\n",
        "        next_state = np.clip(self.state + delta, 0, self.max_index)\n",
        "        if abs(np.sum(next_state) * self.step_size - 3.0) > 0.01:\n",
        "            reward = -1.0  # Invalid move\n",
        "        else:\n",
        "            self.state = next_state\n",
        "            comp = self._state_to_composition(self.state)\n",
        "            reward = self.zt_func(comp)\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "        return self._get_obs(), reward, done, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        comp = self._state_to_composition(self.state)\n",
        "        print(f\"Composition: {comp}\")"
      ],
      "metadata": {
        "id": "QkCMsbW1be4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zt_func(self):\n",
        "    # Store in a DataFrame\n",
        "    #define it based on what we do before\n",
        "    return reward"
      ],
      "metadata": {
        "id": "TLAdMa7SThOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zt_func(self):\n",
        "    # Convert indices to actual property values\n",
        "    # Assuming each index maps to a value in the physical property space\n",
        "    Te = self.Te_idx * 0.3  # Temperature or tellurium content\n",
        "    Se = self.Se_idx * 0.3  # Seebeck coefficient or selenium content\n",
        "    S = self.S_idx * 0.3    # Electrical conductivity or sulfur content\n",
        "\n",
        "    # Calculate zT based on thermoelectric theory\n",
        "    # A common formula for zT is: zT = (SÂ² * Ïƒ * T) / Îº\n",
        "    # where S is Seebeck coefficient, Ïƒ is electrical conductivity,\n",
        "    # T is temperature, and Îº is thermal conductivity\n",
        "\n",
        "    # For this implementation, let's use a simplified model:\n",
        "    # Higher S contributes positively\n",
        "    # Optimal ratio between Te and Se\n",
        "    # Penalize extreme values\n",
        "\n",
        "    # Basic components\n",
        "    seebeck_term = Se**2\n",
        "    conductivity_term = S\n",
        "\n",
        "    # Optimal ratio term (example: best performance when Te:Se is close to 2:1)\n",
        "    ratio_term = 1 - 0.5 * abs((2*Se) - Te) / max(Te, 0.1)\n",
        "\n",
        "    # Thermal properties (simplified)\n",
        "    thermal_term = 1 / (1 + 0.2 * Te)  # Higher Te leads to higher thermal conductivity\n",
        "\n",
        "    # Calculate zT\n",
        "    zt = seebeck_term * conductivity_term * ratio_term * thermal_term\n",
        "\n",
        "    # Add some domain knowledge through constraints\n",
        "    # If values are outside physical ranges, penalize heavily\n",
        "    if Te < 0.3 or Te > 3.0 or Se < 0 or Se > 3.0 or S < 0 or S > 3.0:\n",
        "        zt *= 0.5\n",
        "\n",
        "    # Add some domain-specific features (e.g., known good combinations)\n",
        "    # For example, if Te â‰ˆ 1.5 and Se â‰ˆ 0.9, it's a good composition\n",
        "    if (1.4 < Te < 1.6) and (0.8 < Se < 1.0) and (1.2 < S < 1.8):\n",
        "        zt *= 1.2  # Bonus for known good composition\n",
        "\n",
        "    # Store the result for analysis\n",
        "    self.current_zt = zt\n",
        "\n",
        "    # For reinforcement learning, we want to maximize zT\n",
        "    reward = zt\n",
        "\n",
        "    return reward"
      ],
      "metadata": {
        "id": "qTYMYVAFy5JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Hyperparameters\n",
        "# alpha = 0.1           # learning rate\n",
        "# gamma = 0.99          # discount factor\n",
        "# epsilon = 1.0         # exploration rate\n",
        "# epsilon_decay = 0.995\n",
        "# epsilon_min = 0.01\n",
        "# episodes = 100 #change to your values\n",
        "# max_steps = 100 #change to your values\n",
        "\n",
        "# # Environment and Q-table setup\n",
        "# env = AlloyCompositionEnv(zt_func=zt_func, max_steps=max_steps)\n",
        "# env.reset()\n",
        "# #constructure the initial q_table\n",
        "# state_space = (0, 0, 0)    # change to your values, te_idx, se_idx, s_idx,\n",
        "# action_space = 6              # 6 actions: Â±0.3 for Te, Se, S\n",
        "# q_table = np.zeros(state_space + (action_space,))\n",
        "\n",
        "# # Îµ-greedy action selector\n",
        "# def select_action(state, q_table, epsilon, action_space):\n",
        "#     if np.random.rand() < epsilon:\n",
        "#         return env.action_space.sample()\n",
        "#     else:\n",
        "#         return np.argmax(q_table[tuple(state)])\n",
        "\n",
        "# # Reward tracking\n",
        "# reward_history = []\n",
        "\n",
        "# for episode in range(episodes):\n",
        "#     state, _ = env.reset()\n",
        "#     total_reward = 0\n",
        "#     best_reward = -np.inf\n",
        "\n",
        "#     for step in range(max_steps):\n",
        "#         action = select_action(state, q_table, epsilon, env.action_space)\n",
        "#         next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "#         state_idx = tuple(state)\n",
        "#         next_state_idx = tuple(next_state)\n",
        "\n",
        "#         # Q-learning update\n",
        "#         q_table[state_idx][action] = q_table[state_idx][action] + alpha * (\n",
        "#             reward + gamma * np.max(q_table[next_state_idx]) - q_table[state_idx][action]\n",
        "#         )\n",
        "\n",
        "#         total_reward += reward\n",
        "#         best_reward = max(best_reward, reward)\n",
        "#         state = next_state\n",
        "\n",
        "#         if done:\n",
        "#             break\n",
        "\n",
        "#     # Decay epsilon\n",
        "#     epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "#     reward_history.append(best_reward)\n",
        "\n",
        "#     if episode % 10 == 0:\n",
        "#         print(\"Episode %d: Best zT = %.4f, Îµ = %.3f\" % (episode, best_reward, epsilon))\n",
        "\n",
        "# print(\"Training complete.\")\n"
      ],
      "metadata": {
        "id": "P9TlJKlTTl6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Track the history\n",
        "def track_history(self, state, action, next_state, reward, done=False):\n",
        "    \"\"\"\n",
        "    Track the history of states, actions, and performance metrics.\n",
        "    Call this function after each step in your RL environment.\n",
        "\n",
        "    Parameters:\n",
        "    - state: Tuple or dict representing the state before action (Te_idx, Se_idx, S_idx)\n",
        "    - action: Integer (0-5) representing the action taken\n",
        "    - next_state: Tuple or dict representing the state after action\n",
        "    - reward: Float value (zT) received from the environment\n",
        "    - done: Boolean indicating if the episode has ended\n",
        "    \"\"\"\n",
        "    # Initialize history storage if it doesn't exist\n",
        "    if not hasattr(self, 'history'):\n",
        "        self.history = {\n",
        "            'states': [],\n",
        "            'actions': [],\n",
        "            'rewards': [],\n",
        "            'compositions': [],\n",
        "            'metrics': [],\n",
        "            'best_state': None,\n",
        "            'best_reward': float('-inf'),\n",
        "            'episodes': [],\n",
        "            'current_episode': [],\n",
        "            'episode_count': 0\n",
        "        }\n",
        "\n",
        "    # Unpack states\n",
        "    if isinstance(state, tuple) or isinstance(state, list):\n",
        "        Te_idx, Se_idx, S_idx = state\n",
        "    else:  # Assume dictionary\n",
        "        Te_idx = state.get('Te_idx', state.get(0, 0))\n",
        "        Se_idx = state.get('Se_idx', state.get(1, 0))\n",
        "        S_idx = state.get('S_idx', state.get(2, 0))\n",
        "\n",
        "    if isinstance(next_state, tuple) or isinstance(next_state, list):\n",
        "        next_Te_idx, next_Se_idx, next_S_idx = next_state\n",
        "    else:  # Assume dictionary\n",
        "        next_Te_idx = next_state.get('Te_idx', next_state.get(0, 0))\n",
        "        next_Se_idx = next_state.get('Se_idx', next_state.get(1, 0))\n",
        "        next_S_idx = next_state.get('S_idx', next_state.get(2, 0))\n",
        "\n",
        "    # Convert indices to composition values\n",
        "    Te = Te_idx * 0.3\n",
        "    Se = Se_idx * 0.3\n",
        "    S = S_idx * 0.3\n",
        "\n",
        "    next_Te = next_Te_idx * 0.3\n",
        "    next_Se = next_Se_idx * 0.3\n",
        "    next_S = next_S_idx * 0.3\n",
        "\n",
        "    # Map action to description\n",
        "    action_descriptions = {\n",
        "        0: \"Te +0.3\",\n",
        "        1: \"Te -0.3\",\n",
        "        2: \"Se +0.3\",\n",
        "        3: \"Se -0.3\",\n",
        "        4: \"S +0.3\",\n",
        "        5: \"S -0.3\"\n",
        "    }\n",
        "\n",
        "    # Calculate step metrics\n",
        "    step_size = ((next_Te_idx - Te_idx)**2 +\n",
        "                 (next_Se_idx - Se_idx)**2 +\n",
        "                 (next_S_idx - S_idx)**2)**0.5\n",
        "\n",
        "    # Get current timestamp\n",
        "    import time\n",
        "    timestamp = time.time()\n",
        "\n",
        "    # Build step record\n",
        "    step_record = {\n",
        "        'step': len(self.history['states']),\n",
        "        'state': (Te_idx, Se_idx, S_idx),\n",
        "        'next_state': (next_Te_idx, next_Se_idx, next_S_idx),\n",
        "        'composition': {'Te': Te, 'Se': Se, 'S': S},\n",
        "        'next_composition': {'Te': next_Te, 'Se': next_Se, 'S': next_S},\n",
        "        'action': action,\n",
        "        'action_desc': action_descriptions.get(action, f\"Unknown action {action}\"),\n",
        "        'reward': reward,\n",
        "        'step_size': step_size,\n",
        "        'timestamp': timestamp,\n",
        "        'done': done,\n",
        "        'episode': self.history['episode_count']\n",
        "    }\n",
        "\n",
        "    # Add to current episode\n",
        "    self.history['current_episode'].append(step_record)\n",
        "\n",
        "    # Store in history\n",
        "    self.history['states'].append((Te_idx, Se_idx, S_idx))\n",
        "    self.history['actions'].append(action)\n",
        "    self.history['rewards'].append(reward)\n",
        "    self.history['compositions'].append({'Te': Te, 'Se': Se, 'S': S})\n",
        "    self.history['metrics'].append({\n",
        "        'step_size': step_size,\n",
        "        'timestamp': timestamp\n",
        "    })\n",
        "\n",
        "    # Check if this is the best state found so far\n",
        "    if reward > self.history['best_reward']:\n",
        "        self.history['best_reward'] = reward\n",
        "        self.history['best_state'] = {\n",
        "            'state': (Te_idx, Se_idx, S_idx),\n",
        "            'composition': {'Te': Te, 'Se': Se, 'S': S},\n",
        "            'reward': reward,\n",
        "            'step': len(self.history['states']) - 1,\n",
        "            'episode': self.history['episode_count'],\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "\n",
        "    # If episode is done, finish episode tracking\n",
        "    if done:\n",
        "        episode_data = {\n",
        "            'episode_num': self.history['episode_count'],\n",
        "            'steps': len(self.history['current_episode']),\n",
        "            'start_state': self.history['current_episode'][0]['state'],\n",
        "            'end_state': self.history['current_episode'][-1]['next_state'],\n",
        "            'start_reward': self.history['current_episode'][0]['reward'],\n",
        "            'final_reward': reward,\n",
        "            'improvement': reward - self.history['current_episode'][0]['reward'],\n",
        "            'total_distance': sum(step['step_size'] for step in self.history['current_episode']),\n",
        "            'efficiency': (reward - self.history['current_episode'][0]['reward']) /\n",
        "                         (sum(step['step_size'] for step in self.history['current_episode']) or 1),\n",
        "            'timestamps': {\n",
        "                'start': self.history['current_episode'][0]['timestamp'],\n",
        "                'end': timestamp,\n",
        "                'duration': timestamp - self.history['current_episode'][0]['timestamp']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.history['episodes'].append(episode_data)\n",
        "        self.history['current_episode'] = []\n",
        "        self.history['episode_count'] += 1\n",
        "\n",
        "    return step_record\n",
        "\n",
        "def get_trajectory_analysis(self):\n",
        "    \"\"\"\n",
        "    Analyze the optimization trajectory and return comprehensive statistics.\n",
        "    Call this at the end of training or whenever analysis is needed.\n",
        "    \"\"\"\n",
        "    if not hasattr(self, 'history') or len(self.history['states']) == 0:\n",
        "        return \"No history available for analysis\"\n",
        "\n",
        "    import numpy as np\n",
        "    from collections import Counter\n",
        "\n",
        "    # Basic statistics\n",
        "    total_steps = len(self.history['states'])\n",
        "    total_episodes = self.history['episode_count']\n",
        "    rewards = np.array(self.history['rewards'])\n",
        "\n",
        "    # Trajectory analysis\n",
        "    action_counts = Counter(self.history['actions'])\n",
        "\n",
        "    # Calculate state diversity metrics\n",
        "    unique_states = set(self.history['states'])\n",
        "    state_diversity = len(unique_states) / total_steps if total_steps else 0\n",
        "\n",
        "    # Calculate exploration vs exploitation metrics\n",
        "    exploitation_ratio = sum(1 for i in range(1, total_steps)\n",
        "                           if self.history['rewards'][i] >= self.history['rewards'][i-1]) / (total_steps - 1) if total_steps > 1 else 0\n",
        "\n",
        "    # Performance metrics\n",
        "    if total_episodes > 0:\n",
        "        episode_lengths = [ep['steps'] for ep in self.history['episodes']]\n",
        "        episode_improvements = [ep['improvement'] for ep in self.history['episodes']]\n",
        "        episode_efficiencies = [ep['efficiency'] for ep in self.history['episodes']]\n",
        "    else:\n",
        "        episode_lengths = []\n",
        "        episode_improvements = []\n",
        "        episode_efficiencies = []\n",
        "\n",
        "    # Calculate learning curve\n",
        "    if total_episodes > 0:\n",
        "        episode_final_rewards = [ep['final_reward'] for ep in self.history['episodes']]\n",
        "        learning_curve = {\n",
        "            'episode': list(range(1, total_episodes + 1)),\n",
        "            'final_reward': episode_final_rewards,\n",
        "            'moving_avg_5': [sum(episode_final_rewards[max(0, i-4):i+1]) / min(5, i+1)\n",
        "                             for i in range(total_episodes)]\n",
        "        }\n",
        "    else:\n",
        "        learning_curve = {'episode': [], 'final_reward': [], 'moving_avg_5': []}\n",
        "\n",
        "    # Compile analysis\n",
        "    analysis = {\n",
        "        'total_steps': total_steps,\n",
        "        'total_episodes': total_episodes,\n",
        "        'reward_stats': {\n",
        "            'min': float(rewards.min()) if total_steps else 0,\n",
        "            'max': float(rewards.max()) if total_steps else 0,\n",
        "            'mean': float(rewards.mean()) if total_steps else 0,\n",
        "            'median': float(np.median(rewards)) if total_steps else 0,\n",
        "            'std': float(rewards.std()) if total_steps else 0,\n",
        "            'improvement': float(rewards[-1] - rewards[0]) if total_steps > 1 else 0\n",
        "        },\n",
        "        'best_composition': self.history['best_state'],\n",
        "        'exploration_metrics': {\n",
        "            'unique_states': len(unique_states),\n",
        "            'state_diversity': state_diversity,\n",
        "            'exploitation_ratio': exploitation_ratio,\n",
        "            'action_distribution': {str(k): v for k, v in action_counts.items()}\n",
        "        },\n",
        "        'episode_stats': {\n",
        "            'lengths': {\n",
        "                'min': min(episode_lengths) if episode_lengths else 0,\n",
        "                'max': max(episode_lengths) if episode_lengths else 0,\n",
        "                'mean': sum(episode_lengths) / len(episode_lengths) if episode_lengths else 0\n",
        "            },\n",
        "            'improvements': {\n",
        "                'min': min(episode_improvements) if episode_improvements else 0,\n",
        "                'max': max(episode_improvements) if episode_improvements else 0,\n",
        "                'mean': sum(episode_improvements) / len(episode_improvements) if episode_improvements else 0\n",
        "            },\n",
        "            'efficiencies': {\n",
        "                'min': min(episode_efficiencies) if episode_efficiencies else 0,\n",
        "                'max': max(episode_efficiencies) if episode_efficiencies else 0,\n",
        "                'mean': sum(episode_efficiencies) / len(episode_efficiencies) if episode_efficiencies else 0\n",
        "            }\n",
        "        },\n",
        "        'learning_curve': learning_curve\n",
        "    }\n",
        "\n",
        "    return analysis\n",
        "\n",
        "def visualize_trajectory(self):\n",
        "    \"\"\"\n",
        "    Return data formatted for visualization of the optimization trajectory.\n",
        "\n",
        "    Notes:\n",
        "    - Use this data with plotting libraries like matplotlib or plotly\n",
        "    - For 3D trajectory visualization, use the states data\n",
        "    - For learning curves, use the episode rewards data\n",
        "    \"\"\"\n",
        "    if not hasattr(self, 'history') or len(self.history['states']) == 0:\n",
        "        return \"No history available for visualization\"\n",
        "\n",
        "    # Extract data for various plots\n",
        "    steps = list(range(len(self.history['states'])))\n",
        "    Te_idx_values = [state[0] for state in self.history['states']]\n",
        "    Se_idx_values = [state[1] for state in self.history['states']]\n",
        "    S_idx_values = [state[2] for state in self.history['states']]\n",
        "    rewards = self.history['rewards']\n",
        "\n",
        "    # Trajectory data (for 3D plotting)\n",
        "    trajectory_data = {\n",
        "        'steps': steps,\n",
        "        'Te_idx': Te_idx_values,\n",
        "        'Se_idx': Se_idx_values,\n",
        "        'S_idx': S_idx_values,\n",
        "        'rewards': rewards,\n",
        "        'actions': self.history['actions']\n",
        "    }\n",
        "\n",
        "    # Episode performance data\n",
        "    if len(self.history['episodes']) > 0:\n",
        "        episode_data = {\n",
        "            'episode': list(range(1, len(self.history['episodes']) + 1)),\n",
        "            'final_reward': [ep['final_reward'] for ep in self.history['episodes']],\n",
        "            'improvement': [ep['improvement'] for ep in self.history['episodes']],\n",
        "            'steps': [ep['steps'] for ep in self.history['episodes']],\n",
        "            'efficiency': [ep['efficiency'] for ep in self.history['episodes']]\n",
        "        }\n",
        "    else:\n",
        "        episode_data = {'episode': [], 'final_reward': [], 'improvement': [], 'steps': [], 'efficiency': []}\n",
        "\n",
        "    # Reward over time\n",
        "    reward_data = {\n",
        "        'steps': steps,\n",
        "        'rewards': rewards,\n",
        "        'cumulative_max': [max(rewards[:i+1]) for i in range(len(rewards))]\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'trajectory': trajectory_data,\n",
        "        'episodes': episode_data,\n",
        "        'rewards': reward_data,\n",
        "        'best_state': self.history['best_state']\n",
        "    }"
      ],
      "metadata": {
        "id": "1H6CmYUCdFoX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}